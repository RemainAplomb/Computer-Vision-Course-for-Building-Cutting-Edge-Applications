{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Mrr68q3ZCrY"
   },
   "source": [
    " \n",
    "# <center> <font style=\"color:rgb(255,69,0)\"> Computer Vision Crash Course</font> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EpymkWrZkl1"
   },
   "source": [
    "\n",
    "Name: Rahmani Dibansa\n",
    "\n",
    "Date: 26th of August 2022\n",
    "\n",
    "Description:\n",
    "    This is the optional crashcourse in the Computer Vision For Building Cutting Edge Applications of BleedAI.\n",
    "\n",
    "References:\n",
    "\n",
    "    - BleedAI. Computer Vision For Building Cutting Edge Applications. Lesson 4: (Optional) OpenCV Crash Course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIh-wBkBZCsw"
   },
   "source": [
    "## <font style=\"color:rgb(255,165,0)\"> Read an Image with OpenCV </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHQECqZaZCsy",
    "outputId": "ec814751-6c0d-4c20-cbe9-e4792b4d302c"
   },
   "outputs": [],
   "source": [
    "#this is how you import the Opencv Library\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Since I am using google colab for this crash course,\n",
    "# I included the colab mount\n",
    "#from google.colab import drive\n",
    "#from google.colab.patches import cv2_imshow # cv2.imshow doesn't work on GC\n",
    "#drive.mount('/content/drive')\n",
    "#resources_path = '/content/drive/MyDrive/Colab Notebooks/Computer Vision Crash Course/Media/'\n",
    "resources_path = \"Media/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DE_I5QEIbp-G",
    "outputId": "a6e0bed8-62c7-4fa8-920b-ecf3cc26a8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image path is: Media/two.png\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0 255 255 255 255 255 255 255 255 255 255   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0 255 255   0   0   0   0   0   0   0   0 255 255 255   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 255 255   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 255 255 255   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255 255   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 255 255   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 255 255   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0 255 255 255   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0 255 255   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0 255   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0 255 255   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#we read our Image\n",
    "# This one is for local devices\n",
    "#img = cv2.imread('media/two.png',0)\n",
    "\n",
    "# Loaded the img file from my google drive folder\n",
    "# Check if the path is in proper format, use print\n",
    "print( \" The image path is: \" + resources_path + 'two.png\\n' )\n",
    "img = cv2.imread( resources_path + 'two.PNG', 0)\n",
    "print(img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfmeUOIUZCs9"
   },
   "source": [
    "## <font style=\"color:rgb(255,165,0)\"> Check Image Shape</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SV1_BvKSZCtA",
    "outputId": "4dcfcb0c-2520-4e66-f4c1-d8d8cd966032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image dimension is:  (21, 22)\n"
     ]
    }
   ],
   "source": [
    "# The image's shape is its dimensions\n",
    "# (x, y, color dimension)\n",
    "# The color dimension is how many color there are\n",
    "#       1 and 0: Grayscale\n",
    "#       3: RGB\n",
    "# To learn more of this, go to the documentation page of OpenCV,\n",
    "# and pick your version of OpenCV\n",
    "# https://docs.opencv.org/4.x/\n",
    "print( \" The image dimension is: \" , img.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ-K-8gqZCtD"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Display Image with OpenCV</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "CZut19hzZCtH",
    "outputId": "35173549-a85f-4f46-a886-d30a2e52425c"
   },
   "outputs": [],
   "source": [
    "# Reading the image\n",
    "img = cv2.imread( resources_path + 'two.PNG',0)\n",
    "\n",
    "# Resizing the image to 1000% in size since its too small\n",
    "img = cv2.resize(img, (0,0), fx=10, fy=10)\n",
    "\n",
    "# Display the  image\n",
    "cv2.imshow(\"Module 1: Lesson 4\",img)\n",
    "\n",
    "# Wait for the user to press any key\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy the window after any key is pressed.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShbySnKZZCt2"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Check Image Properties</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XWc5cVs8ZCt5",
    "outputId": "db253994-7345-4203-e7f9-c7681412f831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data type of the Image is: uint8\n",
      "The dimensions of the Image is: 3\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread( resources_path + 'naruto.jpg',1)\n",
    "\n",
    "print('The data type of the Image is: {}'.format(img.dtype))\n",
    "print('The dimensions of the Image is: {}'.format(img.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Llszx7vlZCuA"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Access Pixel values</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AWMdP2vLZCuD",
    "outputId": "24c482d0-b308-418b-bec7-86ee1121ce40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143 161 168]\n",
      "[143 161 168]\n"
     ]
    }
   ],
   "source": [
    "# Check the pixel value that is located on x, y\n",
    "# These are the two ways to do this\n",
    "print(img[300, 300])\n",
    "print(img[300][300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc_X1s7cZCuF"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Change Pixel Value</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ni1VBStJZCuH"
   },
   "outputs": [],
   "source": [
    "# Change the value of the specified pixel\n",
    "# However, since we are changing just one\n",
    "# pixel, we can't really see the change\n",
    "# when we display the image again.\n",
    "# img[300,300] = [255, 0, 255]\n",
    "img[300,300] = 0\n",
    "\n",
    "cv2.imshow(\"Module 0: Lesson 4, Changing Pixel Value\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtMBaQG2ZCuI"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Modify Image ROI</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ppeHGGdnZCuJ"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original Image\n",
    "Img_copy = img.copy()\n",
    "\n",
    "# Modify the Region of Interest (ROI)\n",
    "# You can set the color of a large patch of\n",
    "# the image by doing this...\n",
    "# Img_copy[100:150,80:120]  =  [255, 0, 255]\n",
    "Img_copy[69:420,8:11]  =  0\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Module 0: Lesson 4, Modify the Image ROI \",Img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZfZQ0naZCuJ"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Change Image Size</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_ygpConvZCuK"
   },
   "outputs": [],
   "source": [
    "# Read image in color\n",
    "img = cv2.imread( resources_path + 'narutosage.jpg',1)\n",
    "\n",
    "# Resizing image to a fix x, y size\n",
    "# However, by directly resizing, the\n",
    "# image ratio becomes broken/distorted\n",
    "#resized = cv2.resize(img, (300,300))   \n",
    "\n",
    "# An option to keep the aspect ratio is\n",
    "# to use this method which utilizes\n",
    "# percentages\n",
    "resized = cv2.resize( img, (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Module 0: Lesson 4, Image Resizing\", resized);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joXHzzZ7ZCub"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Change Image Size while maintaining Aspect ratio</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NWtFLliWZCue"
   },
   "outputs": [],
   "source": [
    "# Read image in color\n",
    "img = cv2.imread('Media/narutosage.jpg',1)\n",
    "\n",
    "# Get the width and height of image\n",
    "height, width =  img.shape[:-1]\n",
    "\n",
    "# Compute ratio for the new height taking into account the 300 px width of image\n",
    "r = 300.0 / width\n",
    "\n",
    "# Get the new height\n",
    "new_height = int(height * r)\n",
    "\n",
    "# Resize the image with 300 width and the new height.\n",
    "resized = cv2.resize(img, (300, new_height))\n",
    "\n",
    "# Display Resized Image\n",
    "cv2.imshow(\"Aspect Ratio Resize\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - In this method, you can only specify\n",
    "#             either the height or width. If you\n",
    "#             pick height, the width will adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao4PPOeuZCui"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Translate Image</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zHMX3KSoZCuj"
   },
   "outputs": [],
   "source": [
    "# Read Image\n",
    "img = cv2.imread( resources_path + 'naruto.jpg')\n",
    "\n",
    "# Take the image's shape info\n",
    "rows, cols, channels = img.shape\n",
    "\n",
    "# Construct the translation matrix\n",
    "# [ sideways, upDown ]\n",
    "# [ horizontal, vertical]\n",
    "M = np.float32([\n",
    "    [1,0, 10], \n",
    "    [0,1, 40]\n",
    "])\n",
    "\n",
    "# Apply the warpAffine function\n",
    "# The translation of the image\n",
    "# could either be up, down, or sideways\n",
    "translated = cv2.warpAffine(img, M, (cols,rows))\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Translated Image\",translated);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-f_WpdwZCuo"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Rotate Image</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "e8lWu2RDZCuo"
   },
   "outputs": [],
   "source": [
    "# Set angle to degrees.\n",
    "angle = 90\n",
    "\n",
    "# Rotating image from center with an angle of 90 degrees at the same scale.\n",
    "rotation_matrix = cv2.getRotationMatrix2D((cols/2,rows/2), angle, 1)\n",
    "\n",
    "# apply the transformation\n",
    "rotated = cv2.warpAffine(img, rotation_matrix, (cols,rows))\n",
    "\n",
    "\n",
    "# apply the transformation\n",
    "rotated = cv2.warpAffine(img,rotation_matrix,(cols,rows))\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Rotated Image\",rotated);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2tx6189ZCuq"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Draw a Line</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9WSBmQt8ZCur"
   },
   "outputs": [],
   "source": [
    "copy = img.copy()\n",
    "\n",
    "# Draw a line on the image with these parameters.\n",
    "# This goes line line(image, (x,y), (x2,y2), color, thickness)\n",
    "cv2.line(copy, (250,250),(300,30), (255,255,0), 5) \n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Draw Line\", copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - Here, we learn how to draw lines\n",
    "#             on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6e91lO_ZCut"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Draw a Circle</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4p4XGKEPZCuu"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original image\n",
    "copy = img.copy()\n",
    "\n",
    "# Draw a Circle on naruto’s face with a radius of a 100.\n",
    "# This goes like this..\n",
    "# circle( image, (x,y)/center point , radius, color, thickness )\n",
    "# For filled circles, use thickness -1\n",
    "cv2.circle(copy, (360,200), 50, (255,50,0), 5)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Draw Cirlce\", copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYyasi6LZCuv"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Draw a Rectangle</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "REQAWmGcZCuv"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original image\n",
    "copy = img.copy()\n",
    "\n",
    "# Draw Rectangle around Naruto's face.\n",
    "# rectangle( image, starting point/(x1,y1), end points (x2,y2), color, thickness )\n",
    "cv2.rectangle(copy, (250,100), (450,300), (0,255,255),3)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Draw Rectangle\", copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTElBtPuZCuv"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Put Text</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mKumBVpIZCuw"
   },
   "outputs": [],
   "source": [
    "# If you don't want to read the image, comment it\n",
    "img = cv2.imread( resources_path + 'naruto.jpg')\n",
    "\n",
    "# Make a copy of the original image\n",
    "copy = img.copy()\n",
    "\n",
    "# Write ‘Bleed AI’ on the image\n",
    "# This goes like this\n",
    "# putText ( image, desiredText, (x,y), font type, font size/scale, color, thickness)\n",
    "copy= cv2.putText(copy,'Rahms',(250,470),cv2.FONT_HERSHEY_SIMPLEX, 3, (255,255,0), 4)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Write Text\",copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zt7WEe17ZCux"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\">Cropping the Image</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eNa6iDm6ZCux"
   },
   "outputs": [],
   "source": [
    "# Read Image\n",
    "img = cv2.imread('media/naruto.JPG')\n",
    "\n",
    "# Grab the Face ROI(Region of Interest)\n",
    "face = img[100:270,20:450]\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Image\",face);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tFU-py3ZCux"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Image Smoothing/Blurring</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ICGPsC3eZCuy"
   },
   "outputs": [],
   "source": [
    "# Blur the image\n",
    "# GaussianBlur( image, blur intensity, and some value I cant describe)\n",
    "blurred = cv2.GaussianBlur(img,(1,9), 100)\n",
    "\n",
    "# Display blurred image\n",
    "cv2.imshow(\"Blur\",blurred);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#       - This is for adding noise to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T7ntQ1cZCuy"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Gray Scale Conversion</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "IvwLmaj-ZCuz"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('media/shapes.jpg')\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# Display the grayscale image.\n",
    "cv2.imshow(\"Grayscale Image\", gray_image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - there are different kinds of color conversion\n",
    "#           - COLOR_BGR2GRAY: bgr to grayscale\n",
    "#           - COLOR_RGB2BGR: rgb to bgr\n",
    "#           - COLOR_BGR2RGB: bgr to rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtYG0CDTZCuz"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Thresholding</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "StQoz8jYZCuz"
   },
   "outputs": [],
   "source": [
    "# Apply the threshold\n",
    "# Basically, all pixels within this treshold will\n",
    "# become white. And if it is less than this,\n",
    "# it will become black\n",
    "# (src, thresh, maxValue, cv2.THRESH_BINARY)\n",
    "_ , thresholded_image = cv2.threshold(gray_image, 220, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display original and Threshold image\n",
    "cv2.imshow(\"Thresholded Image\",thresholded_image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCkv9S4-ZCu0"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Inverse Threshold</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3q2L4h0dZCu0"
   },
   "outputs": [],
   "source": [
    "# Apply the threshold\n",
    "_ , thresholded_image = cv2.threshold(gray_image, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Display original and Threshold image\n",
    "cv2.imshow(\"Thresholded Image\",thresholded_image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - This is the inverse tresh binary\n",
    "#           - Basically, if the value is within\n",
    "#             the specified range, it will turn\n",
    "#             black. If not, it will be white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm5X9UaqZCu0"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Edge Detection</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "E07nMb_EZCu1"
   },
   "outputs": [],
   "source": [
    "# Detect Edges in image\n",
    "# image, lower treshold, upper treshold\n",
    "edges = cv2.Canny(img, 30, 150)\n",
    "\n",
    "# Display images\n",
    "cv2.imshow(\"Edge Detection\", edges);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiq9hDCSZCu1"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Finding Contours</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "_U-NSjN5ZCu1"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original image so it won’t be corrupted during drawing\n",
    "image_copy   = img.copy()\n",
    "\n",
    "# Alternatively you can also pass in the edges output to the contours function.\n",
    "# Threshold image, Remember the target object is white and background black.\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "_ , thresholded_image = cv2.threshold(gray_image, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Detect Contours\n",
    "contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Draw the detected contours, -1 means draw all detected contours\n",
    "cv2.drawContours(image_copy , contours, 5 , (0,255,0), 3)\n",
    "\n",
    "# Display image\n",
    "cv2.imshow(\"Contour Detection\", image_copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8nFmyChZCu2"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Count Total Shapes</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "MdXcZ7KVZCu2",
    "outputId": "e9b22c35-c9cf-4112-adb9-081800b3c91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Shapes present in image are: 6\n"
     ]
    }
   ],
   "source": [
    "print('Total Shapes present in image are: {}'.format(len(contours)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br2nneJVZCu3"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Erosion</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "VH2dMsqmZCu3"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread( resources_path + 'whitenoise.png', 0)\n",
    "\n",
    "# Make a 7x7 kernel of ones\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "\n",
    "# Apply erosion with an iteration of 2\n",
    "eroded_image = cv2.erode(img, kernel, iterations = 2)\n",
    "\n",
    "# Display Image\n",
    "cv2.imshow(\"Eroded Image\", eroded_image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - Erosion takes all white points in image\n",
    "#             and removes small white spots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05JrbSiiZCu4"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Dilation</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "lB0nXO4XZCu4"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread( resources_path + 'blacknoise.png',0)\n",
    "\n",
    "# Make a 7x7 kernel of ones\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "\n",
    "# Apply dilation with an iteration of 3\n",
    "dilated_image = cv2.dilate(img, kernel,iterations = 3)\n",
    "\n",
    "# Display Image\n",
    "cv2.imshow(\"Dilation Image\", dilated_image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Additional comments:\n",
    "#           - Erosion takes all black points in image\n",
    "#             and removes small black spots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrPJZ5_MZCu4"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Using Live Webcam Feed</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "MX_dT2kyZCvC"
   },
   "outputs": [],
   "source": [
    "# Initialize Video capture Object.\n",
    "# If you’re using a usb cam then this value can be 1, 2 etc  instead of 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize a loop in which we will read video frame by frame    \n",
    "while(True):\n",
    "    \n",
    "    # Read frame by frame\n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    # If a frame is not read correctly exit the loop, most useful when working with videos on disk\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Now we can perform any image processing operations.\n",
    "    # I’m just going to convert to grayscale and call it a day for this one.\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #frame = cv2.flip (frame, 1)\n",
    "\n",
    "    # Show the frame we just read\n",
    "    cv2.imshow('frame',gray)\n",
    "        \n",
    "    # Wait for the 1 millisecond, before showing the next frame.\n",
    "    #  If the user presses the `q` key then exit the loop.\n",
    "    if cv2.waitKey(1)  ==  ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n",
    "\n",
    "# Destroy the windows you created\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKPBTDkHZCvD"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\"> Face Detection</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "lPQKsv4IZCvE"
   },
   "outputs": [],
   "source": [
    "# Read the image on which we want to apply face detection\n",
    "image = cv2.imread( resources_path + 'family.jpg')\n",
    "\n",
    "# Initializing the haar classifier with the face detector model\n",
    "face_cascade = cv2.CascadeClassifier( resources_path + 'haarcascade_frontalface_default.xml')  \n",
    "\n",
    "# Perform the detection, here we are using 1.3 scale factor and 5 min neighbours\n",
    "detected_faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "\n",
    "# Loop through each face and draw a rectangle on the face coordinates. \n",
    "for (x,y,w,h) in detected_faces:\n",
    "    cv2.rectangle(image, (x,y),(x+w,y+h),(0,255,255),4)\n",
    "    cv2.putText(image, 'Face Detected',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,25), 1, cv2.LINE_AA)  \n",
    " \n",
    "# Display images\n",
    "cv2.imshow(\"Face Detected\", image);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1vGvbM1ZCvF"
   },
   "source": [
    "\n",
    "## <font style=\"color:rgb(255,165,0)\">Image Classification with OpenCV DNN.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ZTD0YazDZCvF"
   },
   "outputs": [],
   "source": [
    "# Split all the classes by a new line and store it in a variable called rows.\n",
    "rows = open('Media/synset_words.txt').read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "LTrevyELZCvG",
    "outputId": "76898c8f-9b31-4144-d026-bdc5b229c9af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes 1000\n"
     ]
    }
   ],
   "source": [
    "# Check the number of classes.\n",
    "print(\"Number of Classes \"+str(len(rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "kdD8jdbkZCvG",
    "outputId": "dfe7e18b-f7f9-4342-80f0-a1a32ea04013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n01440764 tench, Tinca tinca', 'n01443537 goldfish, Carassius auratus', 'n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias', 'n01491361 tiger shark, Galeocerdo cuvieri', 'n01494475 hammerhead, hammerhead shark']\n"
     ]
    }
   ],
   "source": [
    "# Showing the first 5 rows\n",
    "print(rows[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Q79jtr-AZCvH"
   },
   "outputs": [],
   "source": [
    "# Split by comma after the first space is found, grab the first element and store it in a new list.\n",
    "CLASSES = [r[r.find(\" \") + 1:].split(\",\")[0] for r in rows]\n",
    "\n",
    "# Extract first label after the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "fF6C4K2MZCvH",
    "outputId": "f4299070-e521-47de-f27e-419919364a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich', 'brambling', 'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul', 'jay', 'magpie', 'chickadee', 'water ouzel', 'kite', 'bald eagle', 'vulture', 'great grey owl', 'European fire salamander', 'common newt', 'eft', 'spotted salamander', 'axolotl', 'bullfrog', 'tree frog', 'tailed frog', 'loggerhead', 'leatherback turtle', 'mud turtle', 'terrapin', 'box turtle', 'banded gecko', 'common iguana', 'American chameleon', 'whiptail', 'agama', 'frilled lizard', 'alligator lizard', 'Gila monster', 'green lizard', 'African chameleon', 'Komodo dragon', 'African crocodile']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 50 processed class labels \n",
    "print(CLASSES[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "FXihdca3ZCvH"
   },
   "outputs": [],
   "source": [
    "# This is our model weights file\n",
    "weights = 'media/bvlc_googlenet.caffemodel'\n",
    "\n",
    "# This is our model architecture file\n",
    "architecture ='media/bvlc_googlenet.prototxt' \n",
    "\n",
    "# Here we are reading pre-trained caffe model with its architecture \n",
    "net = cv2.dnn.readNetFromCaffe(architecture, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "AkMF8gOYZCvI"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread('media/fish.jpg', 1)\n",
    "\n",
    "# Pre-process the image, with these values.\n",
    "# image, normalizer (could be 1/255), image dimension resize, mean subtraction\n",
    "blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "4HcdSgfUZCvI"
   },
   "outputs": [],
   "source": [
    "# Pass the blob as input through the network \n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "nx4xTgNFZCvJ"
   },
   "outputs": [],
   "source": [
    "# Perform the forward pass\n",
    "Output = net.forward()\n",
    "\n",
    "# This is wehre all the computation happens\n",
    "# the output contains prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "oY6Y3nn_ZCvJ",
    "outputId": "094218ec-c6c1-4dcb-c22b-156355ab46a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Predictions are: 1000\n"
     ]
    }
   ],
   "source": [
    "# Length of the number of predictions\n",
    "print(\"Total Number of Predictions are: {}\".format(len(Output[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "u-KMPRk7ZCvJ",
    "outputId": "120124da-e777-4b06-cfab-2636fa810245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.21623505e-05 9.98483717e-01 5.40039435e-09 4.63203271e-08\n",
      " 1.46981449e-08 9.53976155e-07 1.41101997e-09 9.43035502e-07\n",
      " 1.11431852e-07 3.47780624e-11 1.09527804e-07 2.49070951e-08\n",
      " 4.35384720e-07 1.09612963e-09 8.02260702e-10 5.40932188e-09\n",
      " 2.00019934e-09 6.00098193e-10 5.15555446e-11 4.74514872e-10\n",
      " 8.58447133e-11 1.90390793e-07 3.05192316e-10 1.51088759e-08\n",
      " 1.51897173e-09 6.16359387e-07 5.98880215e-05 1.80176532e-04\n",
      " 1.07785786e-06 2.55477004e-04 1.88719369e-07 5.45301918e-06\n",
      " 2.64027094e-05 2.53552543e-07 5.08394571e-08 6.60278999e-07\n",
      " 1.89136040e-06 8.86264573e-08 5.25027746e-04 3.21332595e-06\n",
      " 6.80621906e-06 2.47658613e-06 1.29752561e-05 1.73193405e-06\n",
      " 1.06492155e-06 3.31225436e-07 1.72064870e-06 4.85999408e-06\n",
      " 3.48619302e-08 1.47008862e-07]\n"
     ]
    }
   ],
   "source": [
    "# These are the probability of each class\n",
    "print(Output[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "l1hKF8ITZCvK",
    "outputId": "f932be67-8fd9-4acb-bfce-bdcd4b76747c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984837\n"
     ]
    }
   ],
   "source": [
    "# Maximum probability\n",
    "print(np.max(Output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Uv2jg4-_ZCvK",
    "outputId": "1e659f59-fd7a-43ce-e78d-eb909788e6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# The index of the class that has been predicted.\n",
    "index = np.argmax(Output[0])\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "fr-bAFT6ZCvL",
    "outputId": "23c9c4aa-3ed7-4151-e200-7016efa31241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish\n"
     ]
    }
   ],
   "source": [
    "# Display the predicted class\n",
    "print(CLASSES[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "SYQp0jVRZCvL"
   },
   "outputs": [],
   "source": [
    "image_copy =  image.copy()\n",
    "\n",
    "# Create text that says the class name and its probability.\n",
    "text = \"Label: {}, {:.2f}%\".format(CLASSES[index], np.max(Output[0])* 100)\n",
    "\n",
    "# Put the text on the image\n",
    "cv2.putText(image_copy, text, (20, 30 ),  cv2.FONT_HERSHEY_COMPLEX, 1, (100, 20, 255), 2)    \n",
    "\n",
    "# Display images\n",
    "cv2.imshow(\"Classified Image\", image_copy);\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VZfZQ0naZCuJ",
    "joXHzzZ7ZCub",
    "Ao4PPOeuZCui",
    "N-f_WpdwZCuo",
    "W2tx6189ZCuq",
    "K6e91lO_ZCut",
    "fYyasi6LZCuv",
    "wTElBtPuZCuv",
    "Zt7WEe17ZCux",
    "2tFU-py3ZCux",
    "4T7ntQ1cZCuy",
    "FtYG0CDTZCuz",
    "zCkv9S4-ZCu0",
    "gm5X9UaqZCu0",
    "aiq9hDCSZCu1",
    "W8nFmyChZCu2",
    "br2nneJVZCu3",
    "05JrbSiiZCu4",
    "nrPJZ5_MZCu4",
    "VKPBTDkHZCvD",
    "-1vGvbM1ZCvF"
   ],
   "name": "Computer Vision Crash Course.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2c83b243fb879010d169f2f59fe1d865a42357da3e2fb5ab94d633edfe058a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
