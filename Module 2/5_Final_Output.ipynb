{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e9b00b-b466-42b6-a404-80f9844924ea",
   "metadata": {},
   "source": [
    "# **<center><font style=\"color:rgb(100,109,254)\">Module 2: Real-Time Controllable Face Makeup</font> </center>**\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=download&id=1ERLn4WIEsSGnAO_4LDT8R8FTf6ac3f5n'>\n",
    "\n",
    "## **<font style=\"color:rgb(134,19,348)\"> Module Outline </font>**\n",
    "\n",
    "The module can be split into the following parts:\n",
    "\n",
    "- *Lesson 1: Introduction to Face Landmark Detection Theory*\n",
    "\n",
    "- *Lesson 2: Create a Face Landmarks Detector*\n",
    "\n",
    "- *Lesson 3: Build a Face Part Selector*\n",
    "\n",
    "- *Lesson 4: Build a Virtual Face Makeup Application*\n",
    "\n",
    "- ***Lesson 5:* Build the Final Application** *(This Tutorial)*\n",
    "\n",
    "**Please Note**, these Jupyter Notebooks are not for sharing; do read the Copyright message below the Code License Agreement section which is in the last cell of this notebook.\n",
    "-Taha Anwar\n",
    "\n",
    "Alright, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2622cc-06e8-4b72-a083-d08dd780f7c7",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\"> Import the Libraries</font>**\n",
    "\n",
    "First, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5c0a50-44dc-43f8-a79c-a0aecdd82b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediapipe version: 0.8.10.1, it should be 0.8.9.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from previous_lesson import (detectFacialLandmarks, detectHandsLandmarks,\n",
    "                             recognizeGestures, calculateDistance,\n",
    "                             selectFacePart, getFacePartMask, applyMakeup)\n",
    "from importlib.metadata import version\n",
    "print(f\"Mediapipe version: {version('mediapipe')}, it should be 0.8.9.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925cac1-b53c-4bf1-8c8a-1e13a217e9ab",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Initialize the Face and Hands Landmarks Detection Models</font>**\n",
    "\n",
    "After that, we will initialize the **`mp.solutions.face_mesh`**, and **`mp.solutions.hands`** classes and then set up the **`mp.solutions.face_mesh.FaceMesh()`**, and **`mp.solutions.hands.Hands()`** functions with appropriate arguments as we have been doing in the previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1f0776-e10a-4faf-a6fc-d11e3792b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe face mesh class.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize the mediapipe hands class.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up the face mesh function with appropriate arguments.\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True,\n",
    "                                  min_detection_confidence=0.8, min_tracking_confidence=0.5)\n",
    "\n",
    "# Set up the Hands function with appropriate arguments.\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                       min_detection_confidence=0.8, min_tracking_confidence=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e4051-f019-4269-88dd-ba9b18dd72dc",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Build the Final Application</font>**\n",
    "\n",
    "Now finally, we will put everything we learned and created in the previous lessons, together to build the final application. We will apply virtual face makeup and modify its intensity in real-time utilizing our hand gestures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fc072f-96d2-43d3-a344-c2e39cf113e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Real-Time Controllable Face Makeup', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize the minimum hue, saturation, and brightness scale factors. \n",
    "min_saturation= min_brightness = 1\n",
    "min_hue = -100\n",
    "\n",
    "# Initialize the maximum hue, saturation, and brightness scale factors. \n",
    "max_saturation= max_brightness = 2\n",
    "max_hue = 100\n",
    "\n",
    "# Initialize a buffer to store recognized gestures.\n",
    "buffer = deque([], maxlen=20)\n",
    "\n",
    "# Create a buffer to store the selected face part.\n",
    "selected_face_part = deque([], maxlen=20)\n",
    "\n",
    "# Initialize the face hue, saturation, and value channel scale factors.\n",
    "face_hsv_value = [1,1.3,1.1]\n",
    "\n",
    "# Initialize the lips hue, saturation, and value channel scale factors.\n",
    "lips_hsv_value = [0,1.6,1.1]\n",
    "\n",
    "# Initialize the eyes hue, saturation, and value channel scale factors.\n",
    "eyes_hsv_value = [1,1,0]\n",
    "\n",
    "# Initialize the eyes hue, saturation, and value channel scale factors.\n",
    "eyebrows_hsv_value = [0,1.6,1.1]\n",
    "\n",
    "# Initialize a variable to store the current mode.\n",
    "current_mode = None\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    # Initialize variables to store hue, saturaton, and brightness scale factors.\n",
    "    hue = saturation = brightness = None\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then \n",
    "    # continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "    \n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Perform Face landmarks detection.\n",
    "    frame, face_landmarks = detectFacialLandmarks(frame, face_mesh, draw=False, display=False)\n",
    "    \n",
    "    # Check if the Face landmarks in the frame are detected.\n",
    "    if len(face_landmarks) > 0:\n",
    "        \n",
    "        # Perform Hands landmarks detection on the frame.\n",
    "        _, hands_results = detectHandsLandmarks(frame, hands, draw=False, display=False)\n",
    "        \n",
    "         # Check if the hands landmarks in the frame are detected.\n",
    "        if hands_results.multi_hand_landmarks:\n",
    "            \n",
    "            # Perform the Face part selection process utilizing the face and hands landmarks.\n",
    "            frame, currently_selected_part = selectFacePart(frame, face_landmarks, hands_results)\n",
    "            \n",
    "            # Check if a face part is selected.\n",
    "            if currently_selected_part:\n",
    "                \n",
    "                # Append the selected Face part into the buffer.\n",
    "                selected_face_part.append(currently_selected_part)\n",
    "                    \n",
    "            # Check if the length of the buffer is equal to 20 i.e. the max length.\n",
    "            if len(selected_face_part) == 20:\n",
    "\n",
    "                # Perform left hand gesture recognition.\n",
    "                current_gesture, size_gesture_tip_pts = recognizeGestures(frame, hands_results,\n",
    "                                                                          hand_label='LEFT',\n",
    "                                                                          draw=False, display=False)\n",
    "\n",
    "                # Check if a known gesture is recognized.\n",
    "                if current_gesture != 'UNKNOWN':\n",
    "\n",
    "                    # Check if all the gestures stored in the buffer are equal to the current gesture.\n",
    "                    if all(current_gesture==gesture for gesture in buffer):\n",
    "\n",
    "                        # Append the current gesture into the buffer.\n",
    "                        buffer.append(current_gesture)\n",
    "\n",
    "                    # Otherwise.\n",
    "                    else:\n",
    "\n",
    "                        # Clear the buffer.\n",
    "                        buffer.clear()\n",
    "\n",
    "                    # Check if the length of the buffer is equal to 20 i.e. the max length.\n",
    "                    if len(buffer) == 5:\n",
    "\n",
    "                        # Calculate the distance between the middle finger tip and thumb tip landmark of the right hand.\n",
    "                        distance = calculateDistance(frame, size_gesture_tip_pts['MIDDLE'],\n",
    "                                                     size_gesture_tip_pts['THUMB'], display=False)\n",
    "\n",
    "\n",
    "                        # Check if the distance is calculated successfully.\n",
    "                        # This will be none in case when the hand is not in the frame.\n",
    "                        if distance:\n",
    "\n",
    "                            # Check if the current hand gesture is INDEX POINTING UP.\n",
    "                            if current_gesture == 'INDEX POINTING UP':\n",
    "                                \n",
    "                                # Get the interpolation function.\n",
    "                                hue_interp_f = interp1d([30,230], [min_hue, max_hue])\n",
    "                                \n",
    "                                # Calculate the hue scale factor based on the calculated distance.\n",
    "                                # Higher the distance, higher the hue scale factor will be.\n",
    "                                hue = hue_interp_f(distance)\n",
    "                                \n",
    "                                # Update the current mode value to Hue.\n",
    "                                current_mode = 'Hue'\n",
    "\n",
    "                            # Check if the current hand gesture is VICTORY.\n",
    "                            elif current_gesture == 'VICTORY':\n",
    "                                \n",
    "                                # Get the interpolation function and calculate the saturation scale factor.\n",
    "                                saturation_interp_f = interp1d([30,230], [min_saturation, max_saturation])\n",
    "                                saturation = saturation_interp_f(distance)\n",
    "                                \n",
    "                                # Update the current mode value to Saturation.\n",
    "                                current_mode = 'Saturation'\n",
    "\n",
    "                            # Check if the current hand gesture is SPIDERMAN.\n",
    "                            elif current_gesture == 'SPIDERMAN':\n",
    "                                \n",
    "                                # Get the interpolation function and calculate the brightness scale factor.\n",
    "                                brightness_interp_f = interp1d([30,230], [min_brightness, max_brightness])\n",
    "                                brightness = brightness_interp_f(distance)\n",
    "                                \n",
    "                                # Update the current mode value to Brightness.\n",
    "                                current_mode = 'Brightness'\n",
    "                            \n",
    "                            if current_mode:\n",
    "                                \n",
    "                                # Get the interpolation function and calculate the bar value.\n",
    "                                # This will be used to draw a filled rectangle of height varying with the distance.\n",
    "                                bar_interp_f = interp1d([30,230],  [frame_height-50, frame_height-400])\n",
    "                                bar_value = bar_interp_f(distance)  \n",
    "\n",
    "                                # Write the current mode on the frame.\n",
    "                                cv2.putText(frame, f'{current_mode} {(distance-30)//2}%',\n",
    "                                            (frame_width//2-(20*len(current_mode)), 40),\n",
    "                                            cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)\n",
    "\n",
    "                                # Draw the filled rectangle with varying height on the frame.\n",
    "                                cv2.rectangle(frame, (frame_width-80, int(bar_value)), \n",
    "                                              (frame_width-50, frame_height-50), (255, 0, 255), -1)\n",
    "\n",
    "                                # Draw another rectangle around the filled rectangle on the frame.\n",
    "                                cv2.rectangle(frame, (frame_width-80, frame_height-400),\n",
    "                                              (frame_width-50, frame_height-50), (0, 255, 0), 6)\n",
    "                        \n",
    "                        # Check if the current hand gesture is HIGH-FIVE.\n",
    "                        if current_gesture == 'HIGH-FIVE':\n",
    "                            \n",
    "                            # Update the hsv scale factors of face, lips, and eyes to zero.\n",
    "                            # This will remove all the makeup from the face.\n",
    "                            face_hsv_value = [0,1,1]\n",
    "                            lips_hsv_value = [0,1,1]\n",
    "                            eyes_hsv_value = [0,1,1]\n",
    "                            \n",
    "                            # Clear the selected face part buffer.\n",
    "                            selected_face_part.clear()\n",
    "                \n",
    "                # Check if the length of the buffer is equal to 20 i.e. the max length.\n",
    "                if len(selected_face_part) == 20:\n",
    "                    \n",
    "                    # Check if the current maximum face part selection results in the buffer are LIPS.\n",
    "                    if max(set(selected_face_part), key=selected_face_part.count) == 'LIPS':\n",
    "\n",
    "                        # Write LIPS Selected text on the frame. \n",
    "                        cv2.putText(frame, 'LIPS Selected.', (5, int(frame_height-20)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "                        \n",
    "                        # Check if a valid hue scale factor value is calculated.\n",
    "                        if hue:\n",
    "                            # Update the hue scale factor in the lips hsv scale factors list.\n",
    "                            lips_hsv_value[0] = hue\n",
    "                        \n",
    "                        # Check if a valid saturation scale factor value is calculated.\n",
    "                        if saturation:\n",
    "                            # Update the saturation scale factor in the lips hsv scale factors list.\n",
    "                            lips_hsv_value[1] = saturation\n",
    "                        \n",
    "                        # Check if a valid brightness scale factor value is calculated.\n",
    "                        if brightness:\n",
    "                            # Update the brightness scale factor in the lips hsv scale factors list.\n",
    "                            lips_hsv_value[2] = brightness\n",
    "\n",
    "\n",
    "                    # Check if the current maximum face part selection results in the buffer are FACE.\n",
    "                    elif max(set(selected_face_part), key=selected_face_part.count) == 'FACE':\n",
    "\n",
    "                        # Write FACE Selected text on the frame. \n",
    "                        cv2.putText(frame, 'FACE Selected.', (5, int(frame_height-20)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "                        # Check if a valid hue scale factor value is calculated.\n",
    "                        if hue:\n",
    "                            # Update the hue scale factor in the face hsv scale factors list.\n",
    "                            face_hsv_value[0] = hue\n",
    "                        \n",
    "                        # Check if a valid saturation scale factor value is calculated.\n",
    "                        if saturation:\n",
    "                            # Update the saturation scale factor in the face hsv scale factors list.\n",
    "                            face_hsv_value[1] = saturation\n",
    "                        \n",
    "                        # Check if a valid brightness scale factor value is calculated.\n",
    "                        if brightness:\n",
    "                            # Update the brightness scale factor in the face hsv scale factors list.\n",
    "                            face_hsv_value[2] = brightness\n",
    "\n",
    "                    # Check if the current maximum face part selection results in the buffer are EYES.\n",
    "                    elif max(set(selected_face_part), key=selected_face_part.count) == 'EYES':\n",
    "\n",
    "                        # Write EYES Selected text on the frame. \n",
    "                        cv2.putText(frame, 'EYES Selected.', (5, int(frame_height-20)),\n",
    "                                     cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "                        \n",
    "                        # Check if a valid hue scale factor value is calculated.\n",
    "                        if hue:\n",
    "                            # Update the hue scale factor in the eyes hsv scale factors list.\n",
    "                            eyes_hsv_value[0] = hue\n",
    "                            \n",
    "                        # Check if a valid saturation scale factor value is calculated.\n",
    "                        if saturation:\n",
    "                            # Update the saturation scale factor in the eyes hsv scale factors list.\n",
    "                            eyes_hsv_value[1] = saturation\n",
    "\n",
    "                        # Check if a valid brightness scale factor value is calculated.\n",
    "                        if brightness:\n",
    "                            # Update the brightness scale factor in the eyes hsv scale factors list.\n",
    "                            eyes_hsv_value[2] = brightness\n",
    "                    # Check if the current maximum face part selection results in the buffer are EYES.\n",
    "                    elif max(set(selected_face_part), key=selected_face_part.count) == 'RIGHT EYEBROW' or max(set(selected_face_part), key=selected_face_part.count) == 'LEFT EYEBROW':\n",
    "\n",
    "                        # Write EYES Selected text on the frame. \n",
    "                        cv2.putText(frame, 'EYEBROWS Selected.', (5, int(frame_height-20)),\n",
    "                                     cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "                        \n",
    "                        # Check if a valid hue scale factor value is calculated.\n",
    "                        if hue:\n",
    "                            # Update the hue scale factor in the eyes hsv scale factors list.\n",
    "                            eyebrows_hsv_value[0] = hue\n",
    "                            \n",
    "                        # Check if a valid saturation scale factor value is calculated.\n",
    "                        if saturation:\n",
    "                            # Update the saturation scale factor in the eyes hsv scale factors list.\n",
    "                            eyebrows_hsv_value[1] = saturation\n",
    "\n",
    "                        # Check if a valid brightness scale factor value is calculated.\n",
    "                        if brightness:\n",
    "                            # Update the brightness scale factor in the eyes hsv scale factors list.\n",
    "                            eyebrows_hsv_value[2] = brightness\n",
    "                            \n",
    "        # Otherwise.\n",
    "        else:\n",
    "            # Clear the buffer.\n",
    "            buffer.clear()\n",
    "            \n",
    "        # Extract the foundation mask of the face in the frame.\n",
    "        face_mask = getFacePartMask(frame, face_landmarks, face_part='FACE', display=False)\n",
    "        \n",
    "        # Extract the lipstick mask of the face in the frame.\n",
    "        lips_mask = getFacePartMask(frame, face_landmarks, face_part='LIPS', display=False)\n",
    "        \n",
    "        # Extract the eyeliner mask of the face in the frame.\n",
    "        eyes_mask = getFacePartMask(frame, face_landmarks, face_part='EYES', display=False)\n",
    "        \n",
    "        # Extract the eyeliner mask of the face in the frame.\n",
    "        eyebrows_mask = getFacePartMask(frame, face_landmarks, face_part='EYEBROWS', display=False)\n",
    "        \n",
    "        # Apply the virtual foundation makeup on the face in the frame.\n",
    "        frame = applyMakeup(frame, face_mask, face_hsv_value, display=False)\n",
    "        \n",
    "        # Apply the virtual lipstick on the face in the frame.\n",
    "        frame = applyMakeup(frame, lips_mask, lips_hsv_value, display=False)\n",
    "        \n",
    "        # Apply the virtual eyeliner on the face in the frame.\n",
    "        frame = applyMakeup(frame, eyes_mask, eyes_hsv_value, display=False)\n",
    "        \n",
    "        # Apply the virtual eyeliner on the face in the frame.\n",
    "        frame = applyMakeup(frame, eyebrows_mask, eyebrows_hsv_value, display=False)\n",
    "    # Display the frame.\n",
    "    cv2.imshow('Real-Time Controllable Face Makeup', frame)\n",
    "    \n",
    "    # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF    \n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if(k == 27):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture Object and close the windows.                  \n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional Comments:\n",
    "#       - In the final output I added in the eyebrow make up function.\n",
    "#         I have tested it, and it does work. However, because of my\n",
    "#         laptop's low specification, there was a lot of lag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e77543-fe27-44af-aad0-3d486f5947af",
   "metadata": {},
   "source": [
    "Smooth! all the components are successfully integrated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f3351-e17b-4acb-8998-69de7a4aeef8",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(255,140,0)\"> Code License Agreement </font>**\n",
    "```\n",
    "Copyright (c) 2022 Bleedai.com\n",
    "\n",
    "Feel free to use this code for your own projects commercial or noncommercial, these projects can be Research-based, just for fun, for-profit, or even Education with the exception that you’re not going to use it for developing a course, book, guide, or any other educational products.\n",
    "\n",
    "Under *NO CONDITION OR CIRCUMSTANCE* you may use this code for your own paid educational or self-promotional ventures without written consent from Taha Anwar (BleedAI.com).\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2c83b243fb879010d169f2f59fe1d865a42357da3e2fb5ab94d633edfe058a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
