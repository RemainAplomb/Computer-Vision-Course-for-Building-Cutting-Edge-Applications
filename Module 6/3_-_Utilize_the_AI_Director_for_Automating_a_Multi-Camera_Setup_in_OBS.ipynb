{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee293f1-a73e-4325-94a9-9456a030a46e",
   "metadata": {},
   "source": [
    "# **<center><font style=\"color:rgb(100,109,254)\">Module 6: AI Video Director For Automating Multi-Camera Setup</font> </center>**\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=19tHZtvNS8ot5c9jvsbjPRk2SkI-8_1_Z' width=800> \n",
    "</center>\n",
    "    \n",
    "\n",
    "## **<font style=\"color:rgb(134,19,348)\"> Module Outline </font>**\n",
    "\n",
    "The module can be split into the following parts:\n",
    "\n",
    "- *Lesson 1: Extract Eyes and Nose Keypoints*\n",
    "\n",
    "- *Lesson 2: Create an AI Director for Automating a Multi-Camera Setup in OpenCV*\n",
    "\n",
    "- ***Lesson 3:* Utilize the AI Director for Automating a Multi-Camera Setup in OBS** *(This Tutorial)* \n",
    "\n",
    "\n",
    "**Please Note**, these Jupyter Notebooks are not for sharing; do read the Copyright message below the Code License Agreement section which is in the last cell of this notebook.\n",
    "-Taha Anwar\n",
    "\n",
    "Alright, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d7220-af48-4577-8f15-46a309afa5dc",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\">Installation & OBS Websocket Setup</font>**\n",
    "\n",
    "First, we will have to install the required [WebSocket API for OBS Studio](https://github.com/obsproject/obs-websocket). You must have [OBS Studio](https://obsproject.com) installed in your system beforehand. To install the WebSocket, you just have to download and run a setup (depending upon the OS, you are using) from the list below.\n",
    "\n",
    "- [obs-websocket-4.9.0-macOS.pkg](https://github.com/obsproject/obs-websocket/releases/download/4.9.0/obs-websocket-4.9.0-macOS.pkg) (for Mac)\n",
    "\n",
    "- [obs-websocket-4.9.0-Windows-Installer.exe](https://github.com/obsproject/obs-websocket/releases/download/4.9.0/obs-websocket-4.9.0-Windows-Installer.exe) (for Windows)\n",
    "\n",
    "- [obs-websocket_4.9.0-1_amd64.deb](https://github.com/obsproject/obs-websocket/releases/download/4.9.0/obs-websocket_4.9.0-1_amd64.deb) (for  Linux)\n",
    "\n",
    "It can be used to remotely control OBS from a phone or tablet on the same local network, change your stream overlay/graphics based on the current scene, and automate scene switching with a third-party program.\n",
    "\n",
    "After that, we will install the Python library ([obs-websocket-py](https://github.com/Elektordi/obs-websocket-py)) required to communicate with an obs-WebSocket server.\n",
    "\n",
    "**Helpful:** [OBS Websocket Python Docs.](https://obs-ws-rc.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3e1f92-e890-4a03-95d4-07e069831956",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: obs-websocket-py in /opt/anaconda3/lib/python3.9/site-packages (0.5.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.9/site-packages (from obs-websocket-py) (1.16.0)\n",
      "Requirement already satisfied: websocket-client in /opt/anaconda3/lib/python3.9/site-packages (from obs-websocket-py) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the required library.\n",
    "!pip install obs-websocket-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f034988-965b-4b88-833c-8cf6e41677e6",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\"> Import the Libraries</font>**\n",
    "\n",
    "After completing all the installations, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fc34b1-00aa-423f-ba9d-0993f101b631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediapipe version: 0.8.9.1, it should be 0.8.9.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import mediapipe as mp\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from importlib.metadata import version\n",
    "print(f\"Mediapipe version: {version('mediapipe')}, it should be 0.8.9.1\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "sys.path.append('../')\n",
    "\n",
    "from obswebsocket import obsws, requests\n",
    "from previous_lesson import detectFacialLandmarks, getFaceKeypoints, getHeadScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f4645-06b0-4709-8d0b-a82ef3617ead",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Connect to the Websocket Server</font>**\n",
    "\n",
    "Now you need to go and launch OBS Studio, Go to **Tools** then click **Web Socket Server Settings** , in the dialog box that pops up, you can change the password to \"**`secret`**\" then click ok. Alright now don't close the OBS application, just minimize it and then run the cell below.\n",
    "\n",
    "Now we will utilize the [obs-websocket-py](https://github.com/Elektordi/obs-websocket-py) library to establish a connection with the obs-WebSocket server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a81dc7-ae81-4bbd-adc7-845603a30796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obswebsocket.core:Connecting...\n",
      "INFO:obswebsocket.core:Connected!\n"
     ]
    }
   ],
   "source": [
    "# Specify the host, port, and the password.\n",
    "host = \"localhost\"\n",
    "port = 4444\n",
    "password = \"secret\"\n",
    "\n",
    "# Connect to the websocket server.\n",
    "ws = obsws(host, port, password)\n",
    "ws.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97304a90-f997-4691-a742-a7553bbbf80e",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Initializations</font>**\n",
    "\n",
    "After that, in this step, we will perform all the required initializations. First, we will initialize a list containing the indexes of the cameras we want to use in this application, then we will initialize the **`mp.solutions.face_mesh`** class and then set up the **`mp.solutions.face_mesh.FaceMesh()`** function with appropriate arguments (for each webcam) as we had done in the previous lesson. We will also create a scene with a `av_capture_input` source for each webcam in OBS studio utilizing the [obs-websocket-py](https://github.com/Elektordi/obs-websocket-py) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084dcb2f-8e6f-468b-813a-a3c1c137db15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize  a list to store the indexes of the cameras.\n",
    "CAMERAS_INDEXES = [0, 1, 2]\n",
    "\n",
    "# Initialize the mediapipe face mesh class.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize a dictionary to store the facemesh functions for different webcam feeds.\n",
    "facemesh_functions = {}\n",
    "\n",
    "# Iterate over the indexes of the cameras.\n",
    "for index in CAMERAS_INDEXES:\n",
    "    \n",
    "    # Make a call to the OBS server through the Websocket and ask to create a new scene.\n",
    "    ws.call(requests.CreateScene('Scene '+ str(index)))\n",
    "    \n",
    "    #NOTE USE THIS 'sourceKind= av_capture_input' if dshow_input does'nt creat actual cameras. dshow_input\n",
    "    # Make another call to the OBS server through the Websocket and ask to create a new video capture source.\n",
    "    ws.call(requests.CreateSource(sourceName='Video Capture Device '+ str(index), sourceKind='av_capture_input', \n",
    "                                  sceneName='Scene '+ str(index), sourceSettings=None))\n",
    "    \n",
    "    # Setup the face landmarks function for the camera.\n",
    "    facemesh_functions[index] = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, \n",
    "                                                      refine_landmarks=True, \n",
    "                                                      min_detection_confidence=0.5, min_tracking_confidence=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad851703-aeb6-4245-b8f5-5944fd16408a",
   "metadata": {},
   "source": [
    "Now we will simply iterate over the sources we have created and display their settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e591819e-a586-44a1-b9fa-b24f3e5bae99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 0', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 0', 'sourceSettings': {}, 'sourceType': 'av_capture_input'})>\n",
      "\n",
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 1', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 1', 'sourceSettings': {}, 'sourceType': 'av_capture_input'})>\n",
      "\n",
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 2', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 2', 'sourceSettings': {}, 'sourceType': 'av_capture_input'})>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the indexes of the cameras.\n",
    "for index in CAMERAS_INDEXES:\n",
    "    \n",
    "    # Make another call to the OBS server through the Websocket and  get the 'Video Capture Device index' source settings.\n",
    "    print(ws.call(requests.GetSourceSettings(sourceName='Video Capture Device '+ str(index))), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96812b17-d82d-4a37-a58c-e5d2ee9c33d6",
   "metadata": {},
   "source": [
    "You may have noticed that the sources we have created don't have a camera (device) specified to them. So for this, you will have to manually go to the OBS studio double-click on the source from the sources list;\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=1DHpN_aAZshHaCryPuOmKDH1La18mXhyP' width=600>\n",
    "</center>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "and then select a camera (device) from the dropdown menu in the poped window and hit ok for each source.\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=15xyd2WQXnDWzunN3VKrLrhIlySK4WBiB' width=600>\n",
    "</center>\n",
    "\n",
    "\n",
    "**Note that** you must select the camera for each source according to the indexes assigned to the cameras in your system. For example, for the source `Video Capture Device 0` you must select the camera which has the index `0`. Now again display the settings of the sources by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c35ae8b-cc0f-488d-9ba5-6a1aa9c49f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 0', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 0', 'sourceSettings': {'device': 'EAB7A68FEC2B4487AADFD8A91C1CB782', 'device_name': 'FaceTime HD Camera'}, 'sourceType': 'av_capture_input'})>\n",
      "\n",
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 1', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 1', 'sourceSettings': {'device': '0x11400017ef4831', 'device_name': 'Lenovo FHD Webcam'}, 'sourceType': 'av_capture_input'})>\n",
      "\n",
      "<GetSourceSettings request ({'sourceName': 'Video Capture Device 2', 'sourceType': None}) called: success ({'sourceName': 'Video Capture Device 2', 'sourceSettings': {'device': '0x11300009da2692', 'device_name': 'A4tech FHD 1080P PC Camera'}, 'sourceType': 'av_capture_input'})>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the indexes of the cameras.\n",
    "for index in CAMERAS_INDEXES:\n",
    "    \n",
    "    # Make another call to the OBS server through the Websocket and  get the 'Video Capture Device i' source settings.\n",
    "    print(ws.call(requests.GetSourceSettings(sourceName='Video Capture Device '+ str(index))), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b588b2d-ab5a-4608-88f3-a285f62da660",
   "metadata": {},
   "source": [
    "You can see that now the sources have a `device` and `device_name` property in the `sourceSettings`. You can note these properties values and next time pass these `sourceSettings` to the **`CreateSource()`** to automate this camera selection process.\n",
    "\n",
    "\n",
    "Now we will utilize the function **`getHeadScore()`** created in the previous lesson, to get the score for each camera and use these values to switch between scenes in OBS studio in real-time depending upon which camera the person is looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4303f4-4115-47c9-b28b-c1edf88f3873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "Running... Scene\n",
      "switched\n",
      "switched\n",
      "switched\n",
      "switched\n",
      "switched\n",
      "switched\n",
      "switched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obswebsocket.core:Disconnecting...\n"
     ]
    }
   ],
   "source": [
    "#Initialize a dictionary to store the VideoCapture objects of different webcams.\n",
    "cameras_readers = {}\n",
    "print('Initializing...')\n",
    "\n",
    "# Iterate over the indexes of the cameras.\n",
    "for camera_index in CAMERAS_INDEXES:\n",
    "    \n",
    "    # Add a VideoCapture object into the dictionary.\n",
    "    cameras_readers[camera_index] = cv2.VideoCapture(camera_index)\n",
    "\n",
    "    # Set the webcam feed width and height.\n",
    "    # cameras_readers[camera_index].set(3,1280)\n",
    "    # cameras_readers[camera_index].set(4,960)\n",
    "\n",
    "# Make a call to the OBS server through the Websocket and \n",
    "# get the list of scenes in the currently active profile.  \n",
    "scenes = ws.call(requests.GetSceneList()).getScenes()\n",
    "\n",
    "# Initialize a variable to store the active scene name.\n",
    "active_scene_name = scenes[0]['name']\n",
    "print('Running...', active_scene_name)\n",
    "\n",
    "# Initialize a buffer to store the scene name with the minimum score.\n",
    "min_score_scene_buffer = deque([], maxlen=3)\n",
    "\n",
    "# Create a try block to avoid the KeyboardInterrupt error,\n",
    "# that is occurred when the kernel is interrupted.\n",
    "# This is done to properly end the program execution when the kernel is interrupted.      \n",
    "try:\n",
    "\n",
    "    # Iterate until a termination (break) statement is executed.\n",
    "    while True:\n",
    "\n",
    "        # Initialize a variable to store the minimum score across all the webcam feeds.\n",
    "        min_score = 1000\n",
    "        \n",
    "        # Initialize a variable to store the scene name with the minimum score.\n",
    "        min_score_scene = active_scene_name\n",
    "        \n",
    "        # Iterate over the VideoCapture objects. \n",
    "        for camera_index, camera_reader in cameras_readers.items():\n",
    "\n",
    "            # Read a frame.\n",
    "            ok, frame = camera_reader.read()\n",
    "\n",
    "            # Check if frame is not read properly then \n",
    "            # continue to the next iteration to read the ne xt frame.\n",
    "            if not ok:\n",
    "                print(f'Failed to read Frame from Camera {camera_index}')\n",
    "                continue\n",
    "\n",
    "            # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Perform Face landmarks detection.\n",
    "            frame, face_landmarks = detectFacialLandmarks(frame, facemesh_functions[camera_index], \n",
    "                                                          draw=False, display=False)\n",
    "            \n",
    "            # Check if the Face landmarks in the frame are detected.\n",
    "            if len(face_landmarks)>0:\n",
    "\n",
    "                # Get the nose, left eye center, and right eye center landmarks.\n",
    "                frame, keypoints = getFaceKeypoints(frame, face_landmarks, draw=False, display=False)\n",
    "\n",
    "                # Calculate the difference between the nose tip and both eyes mid-point.\n",
    "                score = getHeadScore(keypoints)\n",
    "                # print(camera_index, score)\n",
    "\n",
    "                # Check if the calculated score is less than the minimum score.\n",
    "                if score < min_score:\n",
    "\n",
    "                    # Update the minimum score and the scene name with the minimum score.\n",
    "                    min_score = score\n",
    "                    min_score_scene = 'Scene ' + str(camera_index)\n",
    "                    \n",
    "        min_score_scene_buffer.append(min_score_scene)\n",
    "        \n",
    "        # print(min_score_scene_buffer)\n",
    "        \n",
    "        # Check if the scene with the minimum score is not the active scene. \n",
    "        if max(min_score_scene_buffer) != active_scene_name:\n",
    "            \n",
    "            # Make a call to the OBS server through the Websocket and switch the scene.\n",
    "            ws.call(requests.SetCurrentScene(max(min_score_scene_buffer)))\n",
    "            print('switched')\n",
    "            \n",
    "            # Update the active scene name.\n",
    "            active_scene_name = max(min_score_scene_buffer)\n",
    "\n",
    "# Handle the KeyboardInterrupt exception, if it is raised.\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "        \n",
    "# Iterate over the VideoCapture objects. \n",
    "for camera_reader in cameras_readers.values():\n",
    "    \n",
    "    # Release the VideoCapture Object.                  \n",
    "    camera_reader.release()\n",
    "\n",
    "# Close the windows and disconnect from the websocket server.\n",
    "cv2.destroyAllWindows()\n",
    "ws.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a0926-b2c1-4724-9589-16a4d30c3479",
   "metadata": {},
   "source": [
    "Fascinating! right? now you can move around in a multi-camera setup without worrying about manually switching between the cameras you are looking at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fddb90-5bb2-49a1-a438-809a197b11ce",
   "metadata": {},
   "source": [
    "**Below Code is Just For Debugging Purposes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5a0969-5a72-4e7f-8248-8c6857f0eb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cameras_readers = {}\n",
    "CAMERAS_INDEXES =[1,0]\n",
    "\n",
    "# Iterate over the indexes of the cameras.\n",
    "for camera_index in CAMERAS_INDEXES:\n",
    "    \n",
    "    # Add a VideoCapture object into the dictionary.\n",
    "    cameras_readers[camera_index] = cv2.VideoCapture(camera_index)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b311a6-ddee-4187-919a-340d43c9e938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for camera_index, camera_reader in cameras_readers.items():\n",
    "       ok, frame = camera_reader.read()\n",
    "       print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1999a615-a721-4a98-84b5-ac49c581f8a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:obswebsocket.core:Disconnecting...\n",
      "INFO:obswebsocket.core:Connecting...\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\obswebsocket\\core.py\", line 226, in run\n",
      "    message = self.ws.recv()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 362, in recv\n",
      "    opcode, data = self.recv_data()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 385, in recv_data\n",
      "    opcode, frame = self.recv_data_frame(control_frame)\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 406, in recv_data_frame\n",
      "    frame = self.recv_frame()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 445, in recv_frame\n",
      "    return self.frame_buffer.recv_frame()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_abnf.py\", line 341, in recv_frame\n",
      "    self.recv_header()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_abnf.py\", line 297, in recv_header\n",
      "    header = self.recv_strict(2)\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_abnf.py\", line 376, in recv_strict\n",
      "    bytes_ = self.recv(min(16384, shortage))\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 529, in _recv\n",
      "    return recv(self.sock, bufsize)\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_socket.py\", line 125, in recv\n",
      "    raise WebSocketConnectionClosedException(\n",
      "websocket._exceptions.WebSocketConnectionClosedException: Connection to remote host was lost.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\obswebsocket\\core.py\", line 68, in connect\n",
      "    self.ws.connect(\"ws://{}:{}\".format(self.host, self.port))\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_core.py\", line 249, in connect\n",
      "    self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_http.py\", line 130, in connect\n",
      "    sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_http.py\", line 206, in _open_socket\n",
      "    raise err\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\websocket\\_http.py\", line 185, in _open_socket\n",
      "    sock.connect(address)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\obswebsocket\\core.py\", line 245, in run\n",
      "    self.core.reconnect()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\obswebsocket\\core.py\", line 86, in reconnect\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\TEXON WARE\\.conda\\envs\\workingenv\\lib\\site-packages\\obswebsocket\\core.py\", line 73, in connect\n",
      "    raise exceptions.ConnectionFailure(str(e))\n",
      "obswebsocket.exceptions.ConnectionFailure: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the VideoCapture objects. \n",
    "for camera_reader in cameras_readers.values():\n",
    "    \n",
    "    # Release the VideoCapture Object.                  \n",
    "    camera_reader.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c0dda-9edf-4de9-ab98-372ea1bf8058",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(255,140,0)\"> Code License Agreement </font>**\n",
    "```\n",
    "Copyright (c) 2022 Bleedai.com\n",
    "\n",
    "Feel free to use this code for your own projects commercial or noncommercial, these projects can be Research-based, just for fun, for-profit, or even Education with the exception that you’re not going to use it for developing a course, book, guide, or any other educational products.\n",
    "\n",
    "Under *NO CONDITION OR CIRCUMSTANCE* you may use this code for your own paid educational or self-promotional ventures without written consent from Taha Anwar (BleedAI.com).\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
