{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689b1b90-c271-4204-8f72-92731fe6611e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **<center><font style=\"color:rgb(100,109,254)\">Module 7: Physics + Computer Vision</font> </center>**\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=1fZcQOIeX7OVJhsmMH5COSOzbBAxA28UG' width=800> \n",
    "</center>\n",
    "    \n",
    "\n",
    "## **<font style=\"color:rgb(134,19,348)\"> Module Outline </font>**\n",
    "\n",
    "The module can be split into the following parts:\n",
    "\n",
    "- *Lesson 1: Introduction to Pymunk*\n",
    "\n",
    "- *Lesson 2: Integrating Pymunk with OpenCV*\n",
    "\n",
    "- ***Lesson 3:* Build the Final Application** *(This Tutorial)*\n",
    "\n",
    "**Please Note**, these Jupyter Notebooks are not for sharing; do read the Copyright message below the Code License Agreement section which is in the last cell of this notebook.\n",
    "-Taha Anwar\n",
    "\n",
    "Alright, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97a796-ef23-4201-a578-66de9d8784ee",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\"> Import the Libraries</font>**\n",
    "\n",
    "As usual, first, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8e1b89-9ceb-44ee-982f-1b3e557dba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pymunk\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from time import time\n",
    "from collections import deque\n",
    "from previous_lesson import (detectHandsLandmarks, recognizeGestures,\n",
    "                             calculateDistance, rotate, convertPoints, createBall, \n",
    "                             drawBalls, createObstacle, drawObstacles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5f128-425d-4e0c-b700-1574aeb96de5",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Initialize the Hands Landmarks Detection Model</font>**\n",
    "\n",
    "After that, as we have been doing in the previous modules, we will have to initialize the **`mp.solutions.hands`** class and then set up the **`mp.solutions.hands.Hands()`** function with appropriate arguments and also initialize **`mp.solutions.drawing_utils`** class that is needed to visualize the detected landmarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30baa391-e7b4-41c9-b4d2-3e53d9de650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe hands class.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up the Hands functions for videos.\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, \n",
    "                       min_detection_confidence=0.8, min_tracking_confidence=0.8)\n",
    "\n",
    "# Initialize the mediapipe drawing class.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e59b1b-ea2b-4b1a-993b-140d0fb7e47a",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Create a Function to Make Arbitrary Shaped Objects</font>**\n",
    "\n",
    "Now we will create a function **`createObject()`** that will create an arbitrarily shaped object by attaching different line segments to a body utilizing Pymunk's [**`Body`**](http://www.pymunk.org/en/latest/pymunk.html#pymunk.Body) class and the [**`Segment`**](http://www.pymunk.org/en/latest/pymunk.html#pymunk.Segment) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa51937-0d6f-4ece-92de-1b5cd61e436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createObject(frame, drawing_body, start_point, end_point):\n",
    "    '''\n",
    "    This function will create an arbitrary shaped object by attaching different line segments to a body.\n",
    "    Args:\n",
    "        frame:        A frame/image from a real-time webcam feed. \n",
    "        drawing_body: The body of the arbitrary shaped object, that is to be created.\n",
    "        start_point:  The starting point coordinates of the line segment, that is to be attached to the body.\n",
    "        end_point:    The starting point coordinates of the line segment, that is to be attached to the body.\n",
    "    Returns:\n",
    "        drawing_body:       The body of the arbitrary shaped object, after being attached to a new line segment.\n",
    "        drawing_shape:      The line segment shape that is attached to the body.\n",
    "        segment_start_diff: The line segment starting point w.r.t the body position.\n",
    "        segment_end_diff:   The line segment ending point w.r.t the body position.\n",
    "    '''\n",
    "    \n",
    "    # Convert the starting and ending points from OpenCV coordinates system to the Pymunk coordinates system. \n",
    "    start_x, start_y = convertPoints(frame, start_point)\n",
    "    end_x, end_y = convertPoints(frame, end_point)\n",
    "    \n",
    "    # Check if a drawing body is not created.\n",
    "    if not drawing_body:\n",
    "        \n",
    "        # Create a dynamic body for the object. \n",
    "        drawing_body = pymunk.Body(body_type=pymunk.Body.DYNAMIC)\n",
    "        \n",
    "        # Set the body's position equal to the starting point.\n",
    "        drawing_body.position = start_x, start_y\n",
    "    \n",
    "    # Get the position of the body to which we have to attach the shape.\n",
    "    body_x, body_y = drawing_body.position\n",
    "    \n",
    "    # Get the starting and ending points w.r.t the body position.\n",
    "    segment_start_diff =  start_x-body_x, start_y-body_y\n",
    "    segment_end_diff = end_x-body_x, end_y-body_y\n",
    "    \n",
    "    # Create a line segment shape and attach it to the body. \n",
    "    drawing_shape = pymunk.Segment(body=drawing_body, a=segment_start_diff, b=segment_end_diff, radius=brush_size)\n",
    "    \n",
    "    # Set the density of the shape. \n",
    "    drawing_shape.density = 1\n",
    "    \n",
    "    # Set the friction of the shape.\n",
    "    drawing_shape.friction = 1.0\n",
    "    \n",
    "    # Return the body, shape, and the starting and ending points w.r.t the body position.\n",
    "    return drawing_body, drawing_shape, (segment_start_diff, segment_end_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da63899-0ece-4f02-a138-5ea28d596cc6",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Create a Function to Draw Objects</font>**\n",
    "\n",
    "And now we will create a function **`drawObjects()`**, that will utilize the [**`cv2.line()`**](https://docs.opencv.org/4.x/d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2) function to draw all line segments making the arbitrarily shaped objects on a real-time webcam feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f817079-a86f-4410-b666-6b041214d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawObjects(frame, objects_to_draw, brush_size):\n",
    "    '''\n",
    "    This function draws the arbitrary shaped objects on a frame/image.\n",
    "    Args:\n",
    "        frame:           The frame/image to draw objects on, from a real-time webcam feed. \n",
    "        objects_to_draw: A list containing the objects body, and the starting and ending points of the line segments w.r.t the body position.\n",
    "        brush_size:      The thickness of the line segment, that is to be drawn.\n",
    "    Returns:\n",
    "        frame: The frame/image with the objects drawn, from a real-time webcam feed.\n",
    "    '''\n",
    "    \n",
    "    # Iterate over the line segments to draw. \n",
    "    for segment in objects_to_draw:\n",
    "        \n",
    "        # Get the object's body, and the starting and ending points of the line segment w.r.t the body position. \n",
    "        body, (segment_start_diff, segment_end_diff) = segment\n",
    "        \n",
    "        # Get the body's position.\n",
    "        body_x, body_y = body.position\n",
    "        \n",
    "        # Get the starting and ending points coordinates of the line segment on the frame.\n",
    "        start_point =  body_x+segment_start_diff[0], body_y+segment_start_diff[1]\n",
    "        end_point = body_x+segment_end_diff[0], body_y+segment_end_diff[1]\n",
    "        \n",
    "        # Rotate the starting and ending points coordinates w.r.t body angle and position being origin.\n",
    "        start_point = rotate(point=start_point, origin=body.position, angle=body.angle)\n",
    "        end_point = rotate(point=end_point, origin=body.position, angle=body.angle)\n",
    "        \n",
    "        # Draw the line segment on the frame.\n",
    "        cv2.line(img=frame, pt1=convertPoints(frame, start_point), \n",
    "                 pt2=convertPoints(frame, end_point), color=(255,255,255), thickness=brush_size)\n",
    "        \n",
    "    # Return the frame.\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ad578-ef80-4c7a-a724-2ef68d690984",
   "metadata": {},
   "source": [
    "And now we will utilize the functions created above, and in the previous lessons to create balls and arbitrary objects with hand gestures on a real-time webcam feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb526103-f3db-402f-989c-20380cdd9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Get the height and width of the webcam video.\n",
    "height, width = (int(camera_video.get(cv2.CAP_PROP_FRAME_HEIGHT)), \n",
    "                 int(camera_video.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "\n",
    "# Create a named window for resizing purposes.\n",
    "cv2.namedWindow('Webcam Feed', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Create a Space which will contain the simulation.\n",
    "space = pymunk.Space()\n",
    "\n",
    "# Set the gravity.\n",
    "space.gravity = 0, -500 \n",
    "\n",
    "# Initialize a dictionary that will contain the balls, boundary lines, and the objects to draw.\n",
    "to_draw = {'Balls': [], 'boundary_lines': [], 'Objects':[]}\n",
    "\n",
    "# Create line segments and append them into the list inside the dictionary.\n",
    "to_draw['boundary_lines'].append(createObstacle(space, starting_point=(0, 5),\n",
    "                                         ending_point=(width, 5), thickness=20))\n",
    "to_draw['boundary_lines'].append(createObstacle(space, starting_point=(10, 0),\n",
    "                             ending_point=(10, height), thickness=20))\n",
    "to_draw['boundary_lines'].append(createObstacle(space, starting_point=(width-10, 0),\n",
    "                             ending_point=(width-10, height), thickness=20))\n",
    "\n",
    "# Initialize a variable to store the body of the object being created.\n",
    "drawing_body=None\n",
    "\n",
    "# Initialize a list to store the shapes of the object being created. \n",
    "shapes=[]\n",
    "\n",
    "# Initialize a variable to store the brush size (i.e., thickness of the lines forming the object).\n",
    "brush_size = 20\n",
    "\n",
    "# Initialize variables to store previous x and y location.\n",
    "# That are hand brush x and y coordinates in the previous frame.\n",
    "prev_x = None \n",
    "prev_y = None\n",
    "\n",
    "# Initialize a variable to store the buffer length.\n",
    "BUFFER_MAX_LENGTH = 10\n",
    "\n",
    "# Initialize a buffer to store recognized gestures.\n",
    "buffer = deque([], maxlen=BUFFER_MAX_LENGTH)\n",
    "\n",
    "# Initialize a variable to store the frame count.\n",
    "frame_count = 0\n",
    "\n",
    "# Get the start time.\n",
    "start_time = time()\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "   \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then \n",
    "    # continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "        \n",
    "    # Increment the frame counter.\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Perform Hands landmarks detection on the frame.\n",
    "    frame, results = detectHandsLandmarks(frame, hands, draw=True, display=False)\n",
    "    \n",
    "    # Check if the hands landmarks in the frame are detected.\n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        # Perform a hand gesture recognition.\n",
    "        # I have modified this recognizeGestures() function, to return the fingers tips position of the both hands.\n",
    "        current_gesture, hands_tips_positions = recognizeGestures(frame, results, hand_label='LEFT', draw=False,\n",
    "                                                                  display=False)\n",
    "        # Check if a known gesture is recognized.\n",
    "        if current_gesture != 'UNKNOWN':\n",
    "            \n",
    "            # Check if all the gestures stored in the buffer are equal to the current gesture.\n",
    "            if all(current_gesture==gesture for gesture in buffer):\n",
    "                \n",
    "                # Append the current gesture into the buffer.\n",
    "                buffer.append(current_gesture)\n",
    "                \n",
    "            # Otherwise.\n",
    "            else:\n",
    "                \n",
    "                # Clear the buffer.\n",
    "                buffer.clear()\n",
    "            \n",
    "            # Check if the length of the buffer is equal to the maxlength.\n",
    "            if len(buffer) == BUFFER_MAX_LENGTH:\n",
    "                \n",
    "                # Check if the current hand gesture is 'INDEX POINTING UP'.\n",
    "                if current_gesture == 'INDEX POINTING UP':\n",
    "                    \n",
    "                    # Write 'Draw Mode Enabled' on the frame.\n",
    "                    cv2.putText(frame, 'Draw Mode Enabled', (5, int(height-20)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "                    \n",
    "                    # Get the x and y coordinates of tip of the index finger of the right hand.\n",
    "                    x, y = hands_tips_positions['RIGHT']['INDEX']\n",
    "                    \n",
    "                    # Check if the right hand was detected in the frame.\n",
    "                    if x and y:\n",
    "                        \n",
    "                        # Check if the previous x and y donot have valid values.\n",
    "                        if not(prev_x) and not(prev_y):\n",
    "                            \n",
    "                            # Set the previous x and y to the current x and y values.\n",
    "                            prev_x, prev_y = x, y\n",
    "                        \n",
    "                        # Draw a white line on the frame from previous x and y to the current x and y.\n",
    "                        cv2.line(frame, (prev_x, prev_y), (x, y), (255,255,255), brush_size)\n",
    "                        \n",
    "                        # Create an arbitrary shaped object by attaching different line segments to a body. \n",
    "                        drawing_body, drawing_shape, drawing_pts_diff = createObject(frame, drawing_body,\n",
    "                                                                                     (prev_x, prev_y), (x, y))\n",
    "                        # Append the shape into the list.\n",
    "                        shapes.append(drawing_shape)\n",
    "                        \n",
    "                        # Append the body and the points of the line segment w.r.t the body position into the list. \n",
    "                        to_draw['Objects'].append((drawing_body, drawing_pts_diff))\n",
    "                        \n",
    "                        # Update the previous x and y to the current x and y values.\n",
    "                        prev_x, prev_y = x, y\n",
    "                \n",
    "                # Check if the current hand gesture is 'VICTORY'.\n",
    "                elif current_gesture == 'VICTORY':\n",
    "                    \n",
    "                    # Write 'Draw Balls Mode Enabled' on the frame.\n",
    "                    cv2.putText(frame, 'Draw Balls Mode Enabled', (5, int(height-20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "                    \n",
    "                    # Calculate the ball size accordingly to the right hand size.\n",
    "                    ball_size = calculateDistance(frame, point1=hands_tips_positions['RIGHT']['PINKY'],\n",
    "                                                   point2=hands_tips_positions['RIGHT']['THUMB'], draw=False, display=False)\n",
    "                    \n",
    "                    # Check if the ball size is calculated.\n",
    "                    # This will be None in case the right hand was not detected in the frame.\n",
    "                    if ball_size:\n",
    "\n",
    "                        # Calculate the radius of the ball to be created.\n",
    "                        ball_radius = int(ball_size/2)\n",
    "\n",
    "                        # Create a ball at a random x-coordinate value at the top of the frame.\n",
    "                        (ball_body, ball_shape), ball_color = createBall(frame, ball_position=(hands_tips_positions['RIGHT']['MIDDLE']), \n",
    "                                                                         radius=ball_radius)\n",
    "\n",
    "                        # Append the ball's body, shape, radius, and color into the list.\n",
    "                        to_draw['Balls'].append((ball_body, ball_shape, ball_radius, ball_color))\n",
    "\n",
    "                        # Add both the body and the shape of the ball to the simulation.\n",
    "                        space.add(ball_body, ball_shape)\n",
    "                \n",
    "                # Check if the current hand gesture is 'HIGH-FIVE'.\n",
    "                elif current_gesture == 'HIGH-FIVE':\n",
    "                    \n",
    "                    # Write 'Clear Everything' on the frame.\n",
    "                    cv2.putText(img=frame, text='Clear Everything', org=(10, height-30), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                fontScale=1, color=(0,255,0), thickness=2)\n",
    "                    \n",
    "                    # Iterate over the bodies in the space.\n",
    "                    for body in space.bodies:\n",
    "                        \n",
    "                        # Check if the body we are iterating upon, is DYNAMIC.\n",
    "                        if body.body_type == pymunk.Body.DYNAMIC:\n",
    "                            \n",
    "                            # Remove the body and the shapes attached to it, from the space.\n",
    "                            space.remove(body, *list(body.shapes))\n",
    "                            \n",
    "                    # Remove all the balls and the objects from the drawing list as well.\n",
    "                    to_draw['Balls']=[]\n",
    "                    to_draw['Objects']=[]\n",
    "    \n",
    "    # Check if the hands landmarks in the frame are not detected or the current hand gesture is not 'INDEX POINTING UP'.\n",
    "    if not(results.multi_hand_landmarks) or (len(buffer) == 10 and current_gesture != 'INDEX POINTING UP'):\n",
    "        \n",
    "        # Check if the length of shapes list is > 0.\n",
    "        if len(shapes)>0:\n",
    "            \n",
    "            # Add the body and the shapes attached to it, to the space (simulation).\n",
    "            space.add(drawing_body, *shapes)\n",
    "            \n",
    "            # Clear the shapes list.\n",
    "            shapes = []\n",
    "        \n",
    "        # Re-initialize a few variables.\n",
    "        drawing_body=None\n",
    "        prev_x = None\n",
    "        prev_y = None\n",
    "    \n",
    "    # Calaculate average frames per second.\n",
    "    ##################################################################################################\n",
    "    \n",
    "    # Get the current time.\n",
    "    curr_time = time()\n",
    "    \n",
    "    # Check if the difference between the start and current time > 0 to avoid division by zero.\n",
    "    if (curr_time - start_time) > 0:\n",
    "    \n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = frame_count // (curr_time - start_time)\n",
    "        \n",
    "        # Write the calculated number of frames per second on the frame. \n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, int(width/25)),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, int(width/300), (0, 255, 0), int(width/200))\n",
    "    \n",
    "    ##################################################################################################\n",
    "            \n",
    "    # Draw the created balls, the boundary lines and the objects on the frame.\n",
    "    frame = drawObstacles(frame, to_draw['boundary_lines'])\n",
    "    frame = drawObjects(frame, to_draw['Objects'], brush_size)\n",
    "    frame = drawBalls(frame, to_draw['Balls'])\n",
    "    \n",
    "    # Check if the FPS is > 0, to avoid division by zero.\n",
    "    if frames_per_second > 0:\n",
    "        \n",
    "        # Step the simulation one step forward.\n",
    "        space.step(1/frames_per_second)\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow(\"Webcam Feed\", frame)\n",
    "    \n",
    "    # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if k == 27:\n",
    "        break    \n",
    "\n",
    "# Release the VideoCapture Object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Additional information:\n",
    "#           - In summary, this program employed various \n",
    "#             functionalities from the previous lessons.\n",
    "#             Here, we use the hand gestures \"Victory\",\n",
    "#             \"Hand pointing up\", and \"High Five\" to tell\n",
    "#             the program which actions we would like to do.\n",
    "#           - First, when the program starts, we initialize \n",
    "#             the camera, and the Pymunk space.\n",
    "#           - Then, we create the obstacles to prevent the \n",
    "#             objects from falling out of the screen.\n",
    "#           - For the drawing, as long as the user is in drawing\n",
    "#             mode, the program will record the start and end points\n",
    "#             of each stroke that was done. Then, after going out of\n",
    "#             drawing mode, the program will use those to create \n",
    "#             line segments that will be attached to the body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c52ab4-4f8b-4abe-af52-22ae89497256",
   "metadata": {},
   "source": [
    "Cool! right? I bet you didn't expect to create something this amazing with a few simple lines of code. Credit goes to Pymunk of course. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d28c2-2c85-4f3d-b1eb-bc12be857763",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(255,140,0)\"> Code License Agreement </font>**\n",
    "```\n",
    "Copyright (c) 2022 Bleedai.com\n",
    "\n",
    "Feel free to use this code for your own projects commercial or noncommercial, these projects can be Research-based, just for fun, for-profit, or even Education with the exception that you’re not going to use it for developing a course, book, guide, or any other educational products.\n",
    "\n",
    "Under *NO CONDITION OR CIRCUMSTANCE* you may use this code for your own paid educational or self-promotional ventures without written consent from Taha Anwar (BleedAI.com).\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2c83b243fb879010d169f2f59fe1d865a42357da3e2fb5ab94d633edfe058a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
