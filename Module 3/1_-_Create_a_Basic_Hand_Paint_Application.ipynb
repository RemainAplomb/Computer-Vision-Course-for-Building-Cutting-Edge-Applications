{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbed07ed-2560-4f39-8d77-fbe2635189f4",
   "metadata": {},
   "source": [
    "# **<center><font style=\"color:rgb(100,109,254)\">Module 3: Advance Gesture Controlled Shape/Object Manipulation </font></center>**\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=1OGxEgnz1eeMKP-y9dvYtBfV1Zc5VR1to'>\n",
    "    <a href='https://www.microsoft.com/en-us/hololens/developers'>HoloLens photo courtesy of Microsoft</a>\n",
    "</center>\n",
    "\n",
    "\n",
    "## **<font style=\"color:rgb(134,19,348)\"> Module Outline </font>**\n",
    "\n",
    "The module can be split into the following parts:\n",
    "\n",
    "\n",
    "- ***Lesson 1:* Create a Basic Hand Paint Application** *(This Tutorial)*\n",
    "\n",
    "- *Lesson 2: Add Adjustable Paint Color Functionality* \n",
    "\n",
    "- *Lesson 3: Draw Shapes/Objects utilizing Hand Gestures*\n",
    "\n",
    "- *Lesson 4: Manipulate Shapes/Objects utilizing Hand Gestures*\n",
    "\n",
    "**Please Note**, these Jupyter Notebooks are not for sharing; do read the Copyright message below the Code License Agreement section, which is in the last cell of this notebook.\n",
    "-Taha Anwar\n",
    "\n",
    "Alright, without further ado, let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d02784-f11f-44a4-9ac9-0bd72fd66b34",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\"> Import the Libraries</font>**\n",
    "\n",
    "First, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443a5bbd-9b0f-441a-886d-a6da8049d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from collections import deque\n",
    "from previous_lesson import (detectHandsLandmarks, recognizeGestures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb00775-fb09-4775-b741-191a46090d56",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Initialize the Hands Landmarks Detection Model</font>**\n",
    "\n",
    "After that, we will need to initialize the **`mp.solutions.hands`** class and then set up the **`mp.solutions.hands.Hands()`** function with appropriate arguments and also initialize **`mp.solutions.drawing_utils`** class that is needed to visualize the detected landmarks, as we have been doing in the previous lessons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b329934b-5116-41ea-bb49-54e7db467342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe hands class.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up the Hands functions for videos.\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, \n",
    "                       min_detection_confidence=0.8, min_tracking_confidence=0.8)\n",
    "\n",
    "# Initialize the mediapipe drawing class.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07ccdf-bc64-4f80-b463-727e61508977",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Create a Function to Draw utilizing Hands Landmarks</font>**\n",
    "\n",
    "Now we will create a function **`draw()`**, that will simply utilize the hand gestures recognized by the functions from the previous lessons to draw (with the ‚òùÔ∏è Gesture), erase (with the ‚úã Gesture), and Clear all the drawings (with the ü§ü Gesture) from a `canvas` *(i.e. just an empty black image)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b4c0d6-9600-4311-b6f0-35fb3d49054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(frame, canvas, current_gesture, hands_tips_positions, prev_coordinates, paint_color, brush_size=20, eraser_size=80):\n",
    "    '''\n",
    "    This function will draw, erase and clear a canvas based on different hand gestures.\n",
    "    Args:\n",
    "        frame:                A frame/image from the webcam feed.\n",
    "        canvas:               A black image equal to the webcam feed size, to draw on.\n",
    "        current_gesture:      The current gesture of the hand recognized using our gesture recognizer from a previous lesson.\n",
    "        hands_tips_positions: A dictionary containing the landmarks of the tips of the fingers of a hand.\n",
    "        prev_coordinates:     The hand brush x and y coordinates from the previous frame.\n",
    "        paint_color:          The color to draw with, on the canvas.\n",
    "        brush_size:           The size of the paint brush to draw with, on the canvas.\n",
    "        eraser_size:          The size of the eraser to erase with, on the canvas.\n",
    "    Returns:\n",
    "        canvas: The black image with the intented drawings on it, in the paint color.\n",
    "    '''\n",
    "    \n",
    "    # Get the hand brush previous x and y coordinates values (i.e. from the previous frame).\n",
    "    prev_x, prev_y = prev_coordinates\n",
    "    \n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "     # Check if the current hand gesture is INDEX POINTING UP.\n",
    "    if current_gesture == 'INDEX POINTING UP':\n",
    "\n",
    "        # Write the current mode on the frame with the paint color.\n",
    "        cv2.putText(img=frame, text='Paint Mode Enabled', org=(10, frame_height-30),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "                    color=paint_color, thickness=2)\n",
    "\n",
    "        # Get the x and y coordinates of tip of the index finger of the hand.\n",
    "        x, y = hands_tips_positions['INDEX']\n",
    "\n",
    "        # Check if x and y have valid values.\n",
    "        # These will be none if the right hand was not detected in the frame.\n",
    "        # This check will be necessary if you are checking gesture of a different hand and\n",
    "        # want tips landmarks of the different one. But we are not doing that right now,\n",
    "        # so if you want you can remove this check.\n",
    "        if x and y:\n",
    "\n",
    "            # Check if the previous x and y donot have valid values.\n",
    "            if not(prev_x) and not(prev_y):\n",
    "\n",
    "                # Set the previous x and y to the current x and y values.\n",
    "                prev_x, prev_y = x, y\n",
    "\n",
    "            # Draw a line on the canvas from previous x and y to the current x and y with the paint color \n",
    "            # and thickness equal to the brush_size.\n",
    "            cv2.line(img=canvas, pt1=(prev_x, prev_y), pt2=(x, y), color=paint_color, thickness=brush_size)\n",
    "\n",
    "            # Update the previous x and y to the current x and y values.\n",
    "            prev_x, prev_y = x, y\n",
    "\n",
    "        \n",
    "    # Check if the current hand gesture is HIGH-FIVE.\n",
    "    elif current_gesture == 'HIGH-FIVE':\n",
    "\n",
    "        # Write the current mode on the frame.\n",
    "        cv2.putText(img=frame, text='Erase Mode Enabled', org=(10, frame_height-30),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, \n",
    "                    color=paint_color, thickness=2)\n",
    "\n",
    "        # Get the x and y coordinates of tip of the middle finger of the hand.\n",
    "        x1, y = hands_tips_positions['MIDDLE'] \n",
    "\n",
    "        # Get the x coordinate of tip of the ring finger of the hand.\n",
    "        x2, _ = hands_tips_positions['RING'] \n",
    "\n",
    "        # Check if the right hand was detected in the frame.\n",
    "        if x1 and x2 and y:\n",
    "\n",
    "            # Calculate the midpoint between tip x coordinate of the middle and ring finger\n",
    "            x = (x1 + x2) // 2\n",
    "\n",
    "            # Check if the previous x and y donot have valid values.\n",
    "            if not(prev_x) and not(prev_y):\n",
    "\n",
    "                # Set the previous x and y to the current x and y values.\n",
    "                prev_x, prev_y = x, y\n",
    "\n",
    "            # Draw a circle on the frame at the current x and y coordinates, equal to the eraser size.\n",
    "            # This is drawn just to represent an eraser on the current x and y values.\n",
    "            cv2.circle(img=frame, center=(x, y), radius=int(eraser_size/2), color=(255,255,255), thickness=-1)\n",
    "\n",
    "            # Draw a black line on the canvas from previous x and y to the current x and y.\n",
    "            # This will erase the paint between previous x and y and the current x and y.\n",
    "            cv2.line(img=canvas, pt1=(prev_x, prev_y), pt2=(x, y), color=(0,0,0), thickness=eraser_size)\n",
    "\n",
    "            # Update the previous x and y to the current x and y values.\n",
    "            prev_x, prev_y = x, y\n",
    "    \n",
    "    # Check if the current hand gesture is SPIDERMAN.\n",
    "    elif current_gesture == 'SPIDERMAN':\n",
    "\n",
    "        # Write 'Clear Everything' on the frame.\n",
    "        cv2.putText(img=frame, text='Clear Everything', org=(10, frame_height-30), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1, color=paint_color, thickness=2)\n",
    "\n",
    "        # Clear the canvas, by re-initializing it to a complete black image.\n",
    "        canvas = np.zeros((frame_height, frame_width, 3), np.uint8)\n",
    "    \n",
    "    # Return the canvas along with the previous x and y coordinates.\n",
    "    return canvas, (prev_x, prev_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad694b-4e67-412d-aed4-c399db17eea0",
   "metadata": {},
   "source": [
    "And now that we have the **`draw()`** function, we will utilize it to paint with hand gestures on a webcam feed by copying the drawings from the `canvas` to the frames of the video (webcam feed) in real-time, you may be thinking that; why don't we directly draw on the frames. Well to get the intuition behind this, we first need to understand what exactly videos are. It‚Äôs no secret that a video is just a sequence of multiple still images (aka. frames) that are updated really fast creating the appearance of a motion. Consider the video (converted into .gif format) below of a cat jumping on a bookshelf, it is just a combination of 15 different still images that are being updated one after the other.\n",
    "\n",
    "<center><img src='https://lh6.googleusercontent.com/y1-ePQlu3v8HKxuwPHBFxxg70iudUmRhwPiNWMKPKMMyoIl2TSz4jYjgGV_K0XGWrjrxanhIHRqlsgdLbyXFMx8bt1g2hQeQPzwLNW6tpUIr9mBq-53A4msRDBGEqSmsUgzksyC7=s0'></center>\n",
    "\n",
    "\n",
    "So if we draw on a frame then that drawing will disappear from the webcam feed as soon as the frame is updated which normally happens in milliseconds. That's why we need a `canvas` to keep track of all the drawings that we want to visualize on a webcam feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601f2767-058b-4d2c-9a1c-0b4df0d783dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Hand Paint', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize variables to store previous x and y location.\n",
    "# That are hand brush x and y coordinates in the previous frame.\n",
    "prev_x = None \n",
    "prev_y = None\n",
    "\n",
    "# Initialize a canvas to draw on.\n",
    "canvas = np.zeros(shape=(int(camera_video.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "                         int(camera_video.get(cv2.CAP_PROP_FRAME_WIDTH)), 3),\n",
    "                  dtype=np.uint8)\n",
    "\n",
    "# Initialize a variable to store the color value.\n",
    "paint_color = 0, 255, 0\n",
    "\n",
    "# Initialize a variable to store the buffer length.\n",
    "BUFFER_MAX_LENGTH = 10\n",
    "\n",
    "# Initialize a buffer to store recognized gestures.\n",
    "buffer = deque([], maxlen=BUFFER_MAX_LENGTH)\n",
    "\n",
    "# Initialize a variable to store the hand label for gesture recognition.\n",
    "hand_label = 'RIGHT'\n",
    "\n",
    "# Initialize a variable to store the erase mode.\n",
    "erase_mode = False\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "   \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then \n",
    "    # continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    # Perform Hands landmarks detection on the frame.\n",
    "    frame, results = detectHandsLandmarks(frame, hands, draw=True, display=False)\n",
    "    \n",
    "    # Check if the hands landmarks in the frame are detected.\n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        # Perform a hand gesture recognition.\n",
    "        # I have modified this recognizeGestures() function,\n",
    "        # to return the fingers tips position of the both hands.\n",
    "        current_gesture, hands_tips_positions = recognizeGestures(frame, results,\n",
    "                                                                  hand_label, draw=False,\n",
    "                                                                  display=False)\n",
    "        # Check if a known gesture is recognized.\n",
    "        if current_gesture != 'UNKNOWN':\n",
    "            \n",
    "            # Check if all the gestures stored in the buffer are equal to the current gesture.\n",
    "            if all(current_gesture==gesture for gesture in buffer):\n",
    "                \n",
    "                # Append the current gesture into the buffer.\n",
    "                buffer.append(current_gesture)\n",
    "                \n",
    "            # Otherwise.\n",
    "            else:\n",
    "                \n",
    "                # Clear the buffer.\n",
    "                buffer.clear()\n",
    "            \n",
    "            # Check if the length of the buffer is equal to the maxlength, that is 10.\n",
    "            if len(buffer) == BUFFER_MAX_LENGTH:\n",
    "                \n",
    "                # Draw, Erase or Clear the canvas depending upon the current gesture.\n",
    "                canvas, (prev_x, prev_y) = draw(frame, canvas, current_gesture,\n",
    "                                                hands_tips_positions[hand_label],\n",
    "                                                (prev_x, prev_y), paint_color)\n",
    "\n",
    "            # Otherwise.\n",
    "            else:\n",
    "\n",
    "                # Reset, by updating the previous x and y values to None.\n",
    "                # This is required to start a new drawing.\n",
    "                prev_x, prev_y = None, None\n",
    "               \n",
    "    # Otherwise.\n",
    "    else:\n",
    "        \n",
    "        # Clear the buffer.\n",
    "        buffer.clear()\n",
    "        \n",
    "    # Write instructions to switch hand for gesture recognition on the frame.\n",
    "    cv2.putText(img=frame, text=f'{hand_label} hand selected, press s to switch.',\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=paint_color,\n",
    "                thickness=2)\n",
    "\n",
    "    # Update the pixel values of the frame with the canvas's values at the indexes where canvas!=0\n",
    "    # i.e. where canvas is not black and something is drawn there.\n",
    "    # In short, this will copy the drawings from canvas to the frame.\n",
    "    frame[np.mean(canvas, axis=2)!=0] = canvas[np.mean(canvas, axis=2)!=0]\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow(\"Hand Paint\", frame)\n",
    "    \n",
    "   # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # Check if 's' key is pressed and switch the hand label.\n",
    "    elif k == ord('s'):\n",
    "        \n",
    "        # Set gesture hand label to 'LEFT', if it was 'RIGHT',\n",
    "        # Otherwise if it was 'LEFT', set it to 'RIGHT'.\n",
    "        hand_label = 'LEFT' if hand_label == 'RIGHT' else 'RIGHT'\n",
    "        \n",
    "# Release the VideoCapture Object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#           - In summary, we use the hand gesture to draw and erase on\n",
    "#             a black canvas equal to the size of our video screen.\n",
    "#           - The program will keep recording the user's action. If the\n",
    "#             set parameters has been met (i.e. Buffer size and finger positions),\n",
    "#             then, the program will do an action.\n",
    "#           - The user's action will affect the canvas. And in each frame, all\n",
    "#             the pixels that are not black will be copied into the video frame.\n",
    "#           - As for the drawing function, it will take the previous and current \n",
    "#             x and y coordinates of the index finger. Then, it will use that to draw\n",
    "#             a line connecting the two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337002b-c885-416d-85e6-fd0b9f9c9e57",
   "metadata": {},
   "source": [
    "Awesome! the application is working as we intended. We can draw anything we want, but we have only one color option at a time, so let's change that in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6d055-8e1c-477b-ac54-5cf15dde975d",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(255,140,0)\"> Code License Agreement </font>**\n",
    "```\n",
    "Copyright (c) 2022 Bleedai.com\n",
    "\n",
    "Feel free to use this code for your own projects commercial or noncommercial, these projects can be Research-based, just for fun, for-profit, or even Education with the exception that you‚Äôre not going to use it for developing a course, book, guide, or any other educational products.\n",
    "\n",
    "Under *NO CONDITION OR CIRCUMSTANCE* you may use this code for your own paid educational or self-promotional ventures without written consent from Taha Anwar (BleedAI.com).\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2c83b243fb879010d169f2f59fe1d865a42357da3e2fb5ab94d633edfe058a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
