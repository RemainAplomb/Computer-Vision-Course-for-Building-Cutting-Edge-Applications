{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296cad95-4cfa-4ef5-a88e-96a087eda2b6",
   "metadata": {},
   "source": [
    "# **<center><font style=\"color:rgb(100,109,254)\">Module 3: Advance Gesture Controlled Shape/Object Manipulation </font></center>**\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=1OGxEgnz1eeMKP-y9dvYtBfV1Zc5VR1to'>\n",
    "    <a href='https://www.microsoft.com/en-us/hololens/developers'>HoloLens photo courtesy of Microsoft</a>\n",
    "</center>\n",
    "\n",
    "\n",
    "## **<font style=\"color:rgb(134,19,348)\"> Module Outline </font>**\n",
    "\n",
    "The module can be split into the following parts:\n",
    "\n",
    "\n",
    "- *Lesson 1: Create a Basic Hand Paint Application*\n",
    "\n",
    "- ***Lesson 2:* Add Adjustable Paint Color Functionality** *(This Tutorial)*\n",
    "\n",
    "- *Lesson 3: Draw Shapes/Objects utilizing Hand Gestures*\n",
    "\n",
    "- *Lesson 4: Manipulate Shapes/Objects utilizing Hand Gestures*\n",
    "\n",
    "**Please Note**, these Jupyter Notebooks are not for sharing; do read the Copyright message below the Code License Agreement section, which is in the last cell of this notebook.\n",
    "-Taha Anwar\n",
    "\n",
    "Alright, without further ado, let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19624b-493f-433a-abee-ced629b4a44a",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(134,19,348)\"> Import the Libraries</font>**\n",
    "\n",
    "First, we will import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c732b6-6670-4c83-90f1-4fa6e3fdc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from collections import deque\n",
    "from scipy.interpolate import interp1d\n",
    "from previous_lesson import (detectHandsLandmarks, calculateDistance, recognizeGestures, draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47407cc9-bc84-4a88-a2c1-0c822a5c07a9",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Initialize the Hands Landmarks Detection Model</font>**\n",
    "\n",
    "After that, as we have been doing in the previous lessons, we will need to initialize the **`mp.solutions.hands`** class and then set up the **`mp.solutions.hands.Hands()`** function with appropriate arguments and also initialize **`mp.solutions.drawing_utils`** class that is needed to visualize the detected landmarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9334bffa-f752-4913-a1cf-7e9818208f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe hands class.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up the Hands functions for videos.\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, \n",
    "                       min_detection_confidence=0.8, min_tracking_confidence=0.8)\n",
    "\n",
    "# Initialize the mediapipe drawing class.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666eda29-ecaa-44cd-8527-4ab6a5773f74",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Create a Function to Change Paint Color</font>**\n",
    "\n",
    "Now we will create a function **`changePaintColor()`** that will change the color of our paintbrush utilizing hand gestures. As done in the first module, we will use the [**`scipy.interpolate.interp1d()`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html) function to increase/decrease the hue, saturation, and brightness values of the paint color in real-time with the increase/decrease of the distance between the fingers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af72f196-7a31-4887-8c11-db7b5b90a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changePaintColor(frame, paint_color, hand_gesture, distance):\n",
    "    '''\n",
    "    This function will change the paint brush color utilizing hand gestures.\n",
    "    Args:\n",
    "        frame:        The current frame/image (with hands in) of a real-time webcam feed.\n",
    "        paint_color:  The blue, green, and red value of the current paint color.\n",
    "        hand_gesture: The current hand gesture recognized in the frame.\n",
    "        distance:     The distance between the middle finger and the thumb of a hand in the frame.\n",
    "    Returns:\n",
    "        frame         The same frame/image with the current active mode written on it with the paint color.\n",
    "        new_color:    The new blue, green, and red value of the paint color.\n",
    "    '''\n",
    "    \n",
    "    # Check if the current hand gesture is PINKY POINTING UP. \n",
    "    if hand_gesture == 'PINKY POINTING UP':\n",
    "        \n",
    "        # This means that the hue channel [0-179] is to be modified.\n",
    "        # So get the interpolation function accordingly.\n",
    "        color_interp_f = interp1d([30,230], [0, 179])\n",
    "    \n",
    "    # Otherwise.    \n",
    "    else:\n",
    "        \n",
    "        # This means that the saturation or value channel [0-255] is to be modified.\n",
    "        # So get the interpolation function accordingly.\n",
    "        color_interp_f = interp1d([30,230], [0, 255])\n",
    "        \n",
    "    # Calculate the new paint color value.    \n",
    "    new_color_value = color_interp_f(distance)\n",
    "    \n",
    "    # Convert the list into a 8-bit unsigned integer (0 to 255) array.\n",
    "    # And also convert the color space of the paint color from BGR to HSV. \n",
    "    color_hsv = cv2.cvtColor(np.uint8([[paint_color]]), cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Convert the paint color into the float type.\n",
    "    color_hsv = np.array(color_hsv, dtype=np.float64)\n",
    "    \n",
    "    # Split the hue, saturation, and value channel of the paint color.\n",
    "    hue_channel, saturation_channel, value_channel = cv2.split(color_hsv)\n",
    "    \n",
    "    # Check if the current hand gesture is PINKY POINTING UP. \n",
    "    if hand_gesture == 'PINKY POINTING UP':\n",
    "        \n",
    "        # Write the current mode on the frame with the paint color.\n",
    "        cv2.putText(img=frame, text='Change Paint Color Hue', org=(10, 30),fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1, color=paint_color, thickness=2)\n",
    "        \n",
    "        # Update the hue channel value of the paint color.\n",
    "        hue_channel = np.array([[new_color_value]], dtype=np.float64) \n",
    "        \n",
    "    # Check if the current hand gesture is 'MIDDLE RING PINKY POINTING UP'.\n",
    "    elif hand_gesture == 'MIDDLE RING PINKY POINTING UP':\n",
    "        \n",
    "        # Write the current mode on the frame with the paint color.\n",
    "        cv2.putText(img=frame, text='Change Paint Color Saturation', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1, color=paint_color, thickness=2)\n",
    "        \n",
    "        # Update the saturation channel value of the paint color.\n",
    "        saturation_channel = np.array([[new_color_value]], dtype=np.float64) \n",
    "    \n",
    "    # Check if the current hand gesture is ALL FINGERS POINTING UP.\n",
    "    elif hand_gesture == 'ALL FINGERS POINTING UP':\n",
    "        \n",
    "        # Write the current mode on the frame with the paint color.\n",
    "        cv2.putText(img=frame, text='Change Paint Color Brightness', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    fontScale=1, color=paint_color, thickness=2)\n",
    "        \n",
    "\n",
    "        # Update the value channel value of the paint color.\n",
    "        value_channel = np.array([[new_color_value]], dtype=np.float64) \n",
    "\n",
    "    # Merge the Hue, Saturation, and Value channel.\n",
    "    color_hsv = cv2.merge((hue_channel, saturation_channel, value_channel))\n",
    "    \n",
    "    # Clip (limit) the values between 0 and 255.\n",
    "    # This will set values > 255 to 255 and values < 1 to 1.\n",
    "    color_hsv = np.clip(a=color_hsv, a_min=1, a_max=255)\n",
    "    \n",
    "    # Convert the paint color into uint8 type and BGR color space.\n",
    "    # Also flatten the array.\n",
    "    color_bgr = cv2.cvtColor(np.array(color_hsv, dtype=np.uint8), cv2.COLOR_HSV2BGR).flatten()\n",
    "    \n",
    "    # Get the new color bgr values in a tuple.\n",
    "    new_color = (int(color_bgr[0]), int(color_bgr[1]), int(color_bgr[2]))  \n",
    "    \n",
    "    # Return the frame along with the new paint color.\n",
    "    return frame, new_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f07ff-0b98-42b7-a626-90d6bb0e7469",
   "metadata": {},
   "source": [
    "## **<font style=\"color:rgb(134,19,348)\">Create a Function to Visualize Paint Color Range</font>**\n",
    "\n",
    "Now we have a function **`changePaintColor()`**  to change the paint color but without visualization of the possible options it is kind of impossible to choose the one we need. We can try out all the values and then choose the one we liked but that approach is very time-consuming. So now we will create a function  **`vizualizeColorRange()`** that will visualize the paint color range of the selected channel (i.e., Hue, Saturation, or Value) on the frame in real-time whenever we will make the gesture required to change the color.\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img src='https://drive.google.com/uc?export=download&id=1eXTjdnMiA7AIRJjY62pzCt95LOabghXB' width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a9a461-c466-4167-a832-ce7603cb2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualizeColorRange(frame, paint_color_bgr, hand_gesture, distance, BAR_WIDTH=50, BAR_HEIGHT=256*2):\n",
    "    '''\n",
    "    This function will display a range bar of the paint color's hue, saturation, or value channel.\n",
    "    Args:\n",
    "        frame:           The frame/image on which the range bar visualization is required.\n",
    "        paint_color_bgr: The blue, green, and red value of the current paint color.\n",
    "        hand_gesture:    The current hand gesture recognized in the frame.\n",
    "        distance:        The distance between the middle finger and the thumb of a hand in the frame.\n",
    "        BAR_WIDTH:       A constant containing the height of the the range bar image.\n",
    "        BAR_HEIGHT:      A constant containing the width of the the range bar image. This should be a multiple of 256.\n",
    "    Returns:\n",
    "        frame: The frame/image with the range bar of the paint color visualized.\n",
    "    '''\n",
    "    \n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "     \n",
    "    # Convert the list into a 8-bit unsigned integer (0 to 255) array.\n",
    "    # And also convert the color space of the paint color from BGR to HSV. \n",
    "    paint_color_hsv = cv2.cvtColor(np.uint8([[paint_color_bgr]]), cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Convert the paint color into the float type.\n",
    "    paint_color_hsv = np.array(paint_color_hsv, dtype=np.float64)\n",
    "    \n",
    "    # Split the hue, saturation, and value channel of the paint color.\n",
    "    hue, saturation, value = cv2.split(paint_color_hsv)\n",
    "    \n",
    "    # Make a hue channel with all values equal to the hue of the paint color.\n",
    "    hue_channel = hue*np.ones(shape=(int(BAR_HEIGHT/256),BAR_WIDTH), dtype=np.uint8)\n",
    "    \n",
    "    # Make a saturation channel with all values equal to the saturation of the paint color.\n",
    "    saturation_channel = saturation*np.ones(shape=(int(BAR_HEIGHT/256),BAR_WIDTH), dtype=np.uint8)\n",
    "    \n",
    "    # Make a value channel with all values equal to the value (brightness) of the paint color.\n",
    "    value_channel = value*np.ones(shape=(int(BAR_HEIGHT/256),BAR_WIDTH), dtype=np.uint8)\n",
    "    \n",
    "    # Initialize a list to store the range of all possible colors.\n",
    "    colors=[]\n",
    "        \n",
    "    # Iterate over all possible channel values [0-255].\n",
    "    for i in np.arange(0, 256):\n",
    "        \n",
    "        # Check if the current hand gesture is PINKY POINTING UP. \n",
    "        if hand_gesture == 'PINKY POINTING UP':\n",
    "            \n",
    "            # Check if the i is greater than 179.\n",
    "            if i>179:\n",
    "                \n",
    "                # Break the loop.\n",
    "                break\n",
    "\n",
    "            # Make a hue channel with all values equal to i.\n",
    "            hue_channel = i*np.ones((int(BAR_HEIGHT/256), BAR_WIDTH), dtype=np.float64)\n",
    "            \n",
    "        # Check if the current hand gesture is 'MIDDLE RING PINKY POINTING UP'.\n",
    "        elif hand_gesture == 'MIDDLE RING PINKY POINTING UP':\n",
    "            \n",
    "            # Make a saturation channel with all values equal to i.\n",
    "            saturation_channel = i*np.ones((int(BAR_HEIGHT/256), BAR_WIDTH), dtype=np.float64)\n",
    "            \n",
    "        # Check if the current hand gesture is ALL FINGERS POINTING UP.\n",
    "        elif hand_gesture == 'ALL FINGERS POINTING UP':\n",
    "            \n",
    "            # Make a value channel with all values equal to i.\n",
    "            value_channel = i*np.ones((int(BAR_HEIGHT/256), BAR_WIDTH), dtype=np.float64)\n",
    "            \n",
    "        # Merge the Hue, Saturation, and Value channel.\n",
    "        # And also convert the color into a uint8 type array.\n",
    "        color_hsv = np.array(cv2.merge((hue_channel, saturation_channel, value_channel)), dtype=np.uint8)\n",
    "\n",
    "        # Append the color into the colors list.\n",
    "        colors.append(color_hsv)\n",
    "    \n",
    "    # Now we will vertically stack all the colors in the range.\n",
    "    ######################################################################################################################\n",
    "    \n",
    "    # Initialize the range image with the first color in the range list.\n",
    "    # Also Convert it into BGR color space.\n",
    "    resultant_image = cv2.cvtColor(colors[0], cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Iterate from [1 to the length of the colors list].\n",
    "    # We are skipping 0 because we have already initialized the range image with the first color.\n",
    "    # Now we have to iterate over the remaining colors in the range list.\n",
    "    for i in range(1, len(colors)):\n",
    "        \n",
    "        # Convert the ith color in the list into BGR color space.\n",
    "        color_bgr = cv2.cvtColor(colors[i], cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        # Vertically concatenate (stack) the color we are iterating upon into the range image.\n",
    "        resultant_image = cv2.vconcat([color_bgr, resultant_image])\n",
    "        \n",
    "    ######################################################################################################################\n",
    "    \n",
    "    # Resize the resultant image according to the required size.\n",
    "    # As hue channel has lower value range than the other channels so this is done to get a consistent size for the range images.\n",
    "    resultant_image = cv2.resize(resultant_image, dsize=(BAR_WIDTH, BAR_HEIGHT))\n",
    "    \n",
    "    #cv2.imwrite('resultant_image.png', resultant_image)\n",
    "    \n",
    "    # Overlay the resultant image on the frame.\n",
    "    frame[frame_height-600:(frame_height-600)+BAR_HEIGHT,\n",
    "          frame_width-120:(frame_width-120)+BAR_WIDTH] = resultant_image\n",
    "    \n",
    "    # Draw a rectangle around the overlayed range image on the frame.\n",
    "    cv2.rectangle(img=frame, pt1=(frame_width-120, frame_height-600),\n",
    "                  pt2=((frame_width-120)+BAR_WIDTH, (frame_height-600)+BAR_HEIGHT),\n",
    "                  color=(255, 255, 255), thickness=3)\n",
    "\n",
    "\n",
    "    \n",
    "    # Get the interpolation function and calculate the current color bar value.\n",
    "    # This will be used to draw a arrow highlighting the current paint color in the overlayed color range image.\n",
    "    bar_interp_f = interp1d([30,230],  [(frame_height-600)+BAR_HEIGHT, frame_height-600])\n",
    "    bar_value = int(bar_interp_f(distance))\n",
    "\n",
    "    # Get the contour points of the arrow we have to draw.\n",
    "    pts = [(frame_width-150, bar_value+15), (frame_width-150, bar_value-15),\n",
    "           (frame_width-120, bar_value)]\n",
    "\n",
    "    # Draw the filled arrow highlighting the current paint color in the overlayed color range image.\n",
    "    frame = cv2.drawContours(image=frame, contours=[np.array(pts, np.int32)], contourIdx=0, \n",
    "                     color=(255, 255, 255), thickness=-1)\n",
    "    \n",
    "    # Return the frame with the paint color range image overlayed.\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e13d9b-23ba-436c-a240-cc81abe48553",
   "metadata": {},
   "source": [
    "Now that we have the functions **`changePaintColor()`** and **`vizualizeColorRange()`** to add adjustable paint color functionality in our paint application from the previous lesson.  We will utilize a few functions from the first module like the **`recognizeGestures()`** to recognize the hand gestures and **`calculateDistance()`** to get the distance between the middle fingertip and thumb tip landmark of a hand. And then change the paint color based on this distance in rea;-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c596f547-f7fb-4679-9908-df157f6a38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "\n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Hand Paint', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize variables to store previous x and y location.\n",
    "# That are hand brush x and y coordinates in the previous frame.\n",
    "prev_x = None \n",
    "prev_y = None\n",
    "\n",
    "# Initialize a canvas to draw on.\n",
    "canvas = np.zeros(shape=(int(camera_video.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "                         int(camera_video.get(cv2.CAP_PROP_FRAME_WIDTH)), 3),\n",
    "                  dtype=np.uint8)\n",
    "\n",
    "# Initialize a variable to store the color value.\n",
    "paint_color = [0, 255, 0]\n",
    "\n",
    "# Initialize a variable to store the hand label for gesture recognition.\n",
    "hand_label = 'RIGHT'\n",
    "\n",
    "# Initialize a variable to store the buffer length.\n",
    "BUFFER_MAX_LENGTH = 2\n",
    "\n",
    "# Initialize a buffer to store recognized gestures.\n",
    "buffer = deque([], maxlen=BUFFER_MAX_LENGTH)\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "   \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then \n",
    "    # continue to the next iteration to read the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the height and width of the frame of the webcam video.\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    # Perform Hands landmarks detection on the frame.\n",
    "    frame, results = detectHandsLandmarks(frame, hands, draw=True, display=False)\n",
    "    \n",
    "    # Check if the hands landmarks in the frame are detected.\n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        # Perform a hand gesture recognition.\n",
    "        # I have modified this recognizeGestures() function,\n",
    "        # to return the fingers tips position of the both hands.\n",
    "        current_gesture, hands_tips_positions = recognizeGestures(frame, results,\n",
    "                                                                  hand_label, draw=False,\n",
    "                                                                  display=False)\n",
    "        # Check if a known gesture is recognized.\n",
    "        if current_gesture != 'UNKNOWN':\n",
    "            \n",
    "            # Check if all the gestures stored in the buffer are equal to the current gesture.\n",
    "            if all(current_gesture==gesture for gesture in buffer):\n",
    "                \n",
    "                # Append the current gesture into the buffer.\n",
    "                buffer.append(current_gesture)\n",
    "                \n",
    "            # Otherwise.\n",
    "            else:\n",
    "                \n",
    "                # Clear the buffer.\n",
    "                buffer.clear()\n",
    "            \n",
    "            # Check if the length of the buffer is equal to the maxlength, that is 10.\n",
    "            if len(buffer) == BUFFER_MAX_LENGTH:\n",
    "                \n",
    "                # Draw, Erase or Clear the canvas depending upon the current gesture.\n",
    "                canvas, (prev_x, prev_y) = draw(frame, canvas, current_gesture,\n",
    "                                                hands_tips_positions[hand_label],\n",
    "                                                (prev_x, prev_y), paint_color)\n",
    "                \n",
    "                # Check if the current hand gesture is 'PINKY POINTING UP', 'MIDDLE RING PINKY POINTING UP', or 'ALL FINGERS POINTING UP'.\n",
    "                if current_gesture == 'PINKY POINTING UP' or current_gesture == 'MIDDLE RING PINKY POINTING UP' or \\\n",
    "                current_gesture == 'ALL FINGERS POINTING UP':\n",
    "                \n",
    "                    # Calculate the distance between the middle finger tip and thumb tip landmark of the other hand.\n",
    "                    distance = calculateDistance(frame, hands_tips_positions['LEFT' if hand_label == 'RIGHT' else 'RIGHT']['MIDDLE'],\n",
    "                                                 hands_tips_positions['LEFT' if hand_label == 'RIGHT' else 'RIGHT']['THUMB'], display=False)\n",
    "\n",
    "                    # Check if the distance is calculated successfully.\n",
    "                    # This will be none in case when the hand is not in the frame.\n",
    "                    if distance:\n",
    "                        \n",
    "                        # Write the current distance percentage on the frame.\n",
    "                        cv2.putText(img=frame, text=f'{int((distance-30)/2)}%',org=(frame_width-130, frame_height-630), \n",
    "                                    fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=3, color=paint_color, thickness=3)\n",
    "                        \n",
    "                        \n",
    "                        # Change the paint color utilizing hand gestures.\n",
    "                        frame, paint_color = changePaintColor(frame, paint_color, current_gesture, distance)\n",
    "                        \n",
    "                        # Display the paint color range.\n",
    "                        frame = vizualizeColorRange(frame, paint_color, current_gesture, distance)\n",
    "                        \n",
    "                    \n",
    "            # Otherwise.\n",
    "            else:\n",
    "\n",
    "                # Reset, by updating the previous x and y values to None.\n",
    "                # This is required to start a new drawing.\n",
    "                prev_x = None\n",
    "                prev_y = None\n",
    "               \n",
    "    # Otherwise.\n",
    "    else:\n",
    "        \n",
    "        # Clear the buffer.\n",
    "        buffer.clear()\n",
    "\n",
    "    # Update the pixel values of the frame with the canvas's values at the indexes where canvas!=0\n",
    "    # i.e. where canvas is not black and something is drawn there.\n",
    "    # In short, this will copy the drawings from canvas to the frame.\n",
    "    frame[np.mean(canvas, axis=2)!=0] = canvas[np.mean(canvas, axis=2)!=0]\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow(\"Hand Paint\", frame)\n",
    "    \n",
    "   # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # Check if 's' key is pressed and switch the hand label.\n",
    "    elif k == ord('s'):\n",
    "        \n",
    "        # Set gesture hand label to 'LEFT', if it was 'RIGHT',\n",
    "        # Otherwise if it was 'LEFT', set it to 'RIGHT'.\n",
    "        hand_label = 'LEFT' if hand_label == 'RIGHT' else 'RIGHT'\n",
    "        \n",
    "# Release the VideoCapture Object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional comments:\n",
    "#       - Since my device has low specs, I brought down the buffer size\n",
    "#         it helped a lot in detection, and the program was able to \n",
    "#         recognize my gestures.\n",
    "#       - However, I think for better computers that has higher FPS, it\n",
    "#         is recommended to bring the buffer size back to 20 or even a \n",
    "#         little higher.\n",
    "#       - Apart from that, I encountered a problem with this program \n",
    "#         while testing it.\n",
    "#       - If i remove these: \n",
    "#               camera_video.set(3,1280)\n",
    "#               camera_video.set(4,960)\n",
    "#         I get an error with the shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f974ad34-3a79-45dc-9e38-4f076c167814",
   "metadata": {},
   "source": [
    "Great! paint colors are changing as we intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0ef97-e52a-412d-a3f7-96fcc65210bc",
   "metadata": {},
   "source": [
    "### **<font style=\"color:rgb(255,140,0)\"> Code License Agreement </font>**\n",
    "```\n",
    "Copyright (c) 2022 Bleedai.com\n",
    "\n",
    "Feel free to use this code for your own projects commercial or noncommercial, these projects can be Research-based, just for fun, for-profit, or even Education with the exception that you’re not going to use it for developing a course, book, guide, or any other educational products.\n",
    "\n",
    "Under *NO CONDITION OR CIRCUMSTANCE* you may use this code for your own paid educational or self-promotional ventures without written consent from Taha Anwar (BleedAI.com).\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2c83b243fb879010d169f2f59fe1d865a42357da3e2fb5ab94d633edfe058a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
